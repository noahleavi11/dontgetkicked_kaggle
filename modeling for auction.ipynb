{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this code is to create a model that will correctly predict whether or not a car in an aution will be a worthwhile purchase or not. The original kaggle challenge can be found at https://www.kaggle.com/c/DontGetKicked/overview. This python file only contains the modeling I did on the data. You will find in the R file the work I did to extract features I thought would be important in a final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in given training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"pytrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>IsBadBuy_no</th>\n",
       "      <th>IsBadBuy_yes</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction_ADESA</th>\n",
       "      <th>Auction_MANHEIM</th>\n",
       "      <th>Auction_OTHER</th>\n",
       "      <th>generalMake_AMERICAN</th>\n",
       "      <th>generalMake_CHEVROLET</th>\n",
       "      <th>...</th>\n",
       "      <th>Transmission_AUTO</th>\n",
       "      <th>Transmission_MANUAL</th>\n",
       "      <th>VehOdo</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>MMRAcqAucAvg</th>\n",
       "      <th>MMRAcqRetAvg</th>\n",
       "      <th>MMRCurrAucAvg</th>\n",
       "      <th>MMRCurrRetAvg</th>\n",
       "      <th>WarrantyCost</th>\n",
       "      <th>BYRNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89046</td>\n",
       "      <td>7100.0</td>\n",
       "      <td>8155</td>\n",
       "      <td>11636</td>\n",
       "      <td>7451</td>\n",
       "      <td>11597</td>\n",
       "      <td>1113</td>\n",
       "      <td>21973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93593</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>6854</td>\n",
       "      <td>10897</td>\n",
       "      <td>7456</td>\n",
       "      <td>11374</td>\n",
       "      <td>1053</td>\n",
       "      <td>19638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73807</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>3202</td>\n",
       "      <td>6943</td>\n",
       "      <td>4035</td>\n",
       "      <td>7146</td>\n",
       "      <td>1389</td>\n",
       "      <td>19638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65617</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>1893</td>\n",
       "      <td>4658</td>\n",
       "      <td>1844</td>\n",
       "      <td>4375</td>\n",
       "      <td>630</td>\n",
       "      <td>19638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69367</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>3913</td>\n",
       "      <td>7723</td>\n",
       "      <td>3247</td>\n",
       "      <td>6739</td>\n",
       "      <td>1020</td>\n",
       "      <td>19638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RefId  IsBadBuy_no  IsBadBuy_yes  VehYear  PurchDate  Auction_ADESA  \\\n",
       "0      1            0             1     2006       2009              1   \n",
       "1      2            0             1     2004       2009              1   \n",
       "2      3            0             1     2005       2009              1   \n",
       "3      4            0             1     2004       2009              1   \n",
       "4      5            0             1     2005       2009              1   \n",
       "\n",
       "   Auction_MANHEIM  Auction_OTHER  generalMake_AMERICAN  \\\n",
       "0                0              0                     0   \n",
       "1                0              0                     0   \n",
       "2                0              0                     0   \n",
       "3                0              0                     0   \n",
       "4                0              0                     0   \n",
       "\n",
       "   generalMake_CHEVROLET  ...  Transmission_AUTO  Transmission_MANUAL  VehOdo  \\\n",
       "0                      0  ...                  1                    0   89046   \n",
       "1                      0  ...                  1                    0   93593   \n",
       "2                      0  ...                  1                    0   73807   \n",
       "3                      0  ...                  1                    0   65617   \n",
       "4                      0  ...                  0                    1   69367   \n",
       "\n",
       "   VehBCost  MMRAcqAucAvg  MMRAcqRetAvg  MMRCurrAucAvg  MMRCurrRetAvg  \\\n",
       "0    7100.0          8155         11636           7451          11597   \n",
       "1    7600.0          6854         10897           7456          11374   \n",
       "2    4900.0          3202          6943           4035           7146   \n",
       "3    4100.0          1893          4658           1844           4375   \n",
       "4    4000.0          3913          7723           3247           6739   \n",
       "\n",
       "   WarrantyCost  BYRNO  \n",
       "0          1113  21973  \n",
       "1          1053  19638  \n",
       "2          1389  19638  \n",
       "3           630  19638  \n",
       "4          1020  19638  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop([\"IsBadBuy_yes\", \"generalMake_NULL\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading in test data set (used for submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"pytest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction_ADESA</th>\n",
       "      <th>Auction_MANHEIM</th>\n",
       "      <th>Auction_OTHER</th>\n",
       "      <th>generalMake_AMERICAN</th>\n",
       "      <th>generalMake_CHEVROLET</th>\n",
       "      <th>generalMake_CHRYSLER</th>\n",
       "      <th>generalMake_DODGE</th>\n",
       "      <th>...</th>\n",
       "      <th>Transmission_AUTO</th>\n",
       "      <th>Transmission_MANUAL</th>\n",
       "      <th>VehOdo</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>MMRAcqAucAvg</th>\n",
       "      <th>MMRAcqRetAvg</th>\n",
       "      <th>MMRCurrAucAvg</th>\n",
       "      <th>MMRCurrRetAvg</th>\n",
       "      <th>WarrantyCost</th>\n",
       "      <th>BYRNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73015</td>\n",
       "      <td>2005</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85377</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>5032</td>\n",
       "      <td>5935</td>\n",
       "      <td>4905</td>\n",
       "      <td>8557</td>\n",
       "      <td>2152</td>\n",
       "      <td>18881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73016</td>\n",
       "      <td>2005</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61873</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>4502</td>\n",
       "      <td>5362</td>\n",
       "      <td>4645</td>\n",
       "      <td>7562</td>\n",
       "      <td>1118</td>\n",
       "      <td>18111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73017</td>\n",
       "      <td>2006</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69283</td>\n",
       "      <td>9700.0</td>\n",
       "      <td>10244</td>\n",
       "      <td>11564</td>\n",
       "      <td>10883</td>\n",
       "      <td>15340</td>\n",
       "      <td>1215</td>\n",
       "      <td>18111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73018</td>\n",
       "      <td>2002</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>87889</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>2558</td>\n",
       "      <td>3263</td>\n",
       "      <td>2928</td>\n",
       "      <td>5725</td>\n",
       "      <td>1933</td>\n",
       "      <td>18881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73019</td>\n",
       "      <td>2007</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73432</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>5013</td>\n",
       "      <td>5914</td>\n",
       "      <td>5013</td>\n",
       "      <td>5914</td>\n",
       "      <td>920</td>\n",
       "      <td>18111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RefId  VehYear  PurchDate  Auction_ADESA  Auction_MANHEIM  Auction_OTHER  \\\n",
       "0  73015     2005       2009              1                0              0   \n",
       "1  73016     2005       2009              1                0              0   \n",
       "2  73017     2006       2009              1                0              0   \n",
       "3  73018     2002       2009              1                0              0   \n",
       "4  73019     2007       2009              1                0              0   \n",
       "\n",
       "   generalMake_AMERICAN  generalMake_CHEVROLET  generalMake_CHRYSLER  \\\n",
       "0                     0                      0                     0   \n",
       "1                     0                      1                     0   \n",
       "2                     0                      0                     0   \n",
       "3                     0                      0                     0   \n",
       "4                     0                      0                     0   \n",
       "\n",
       "   generalMake_DODGE  ...  Transmission_AUTO  Transmission_MANUAL  VehOdo  \\\n",
       "0                  0  ...                  1                    0   85377   \n",
       "1                  0  ...                  1                    0   61873   \n",
       "2                  1  ...                  1                    0   69283   \n",
       "3                  0  ...                  1                    0   87889   \n",
       "4                  0  ...                  1                    0   73432   \n",
       "\n",
       "   VehBCost  MMRAcqAucAvg  MMRAcqRetAvg  MMRCurrAucAvg  MMRCurrRetAvg  \\\n",
       "0    6500.0          5032          5935           4905           8557   \n",
       "1    6300.0          4502          5362           4645           7562   \n",
       "2    9700.0         10244         11564          10883          15340   \n",
       "3    4150.0          2558          3263           2928           5725   \n",
       "4    4100.0          5013          5914           5013           5914   \n",
       "\n",
       "   WarrantyCost  BYRNO  \n",
       "0          2152  18881  \n",
       "1          1118  18111  \n",
       "2          1215  18111  \n",
       "3          1933  18881  \n",
       "4           920  18111  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64007\n",
       "1     8976\n",
       "Name: IsBadBuy_no, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"IsBadBuy_no\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(101)\n",
    "X = train.drop([\"IsBadBuy_no\",\"RefId\"], axis=1)\n",
    "y = train[\"IsBadBuy_no\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Train and Test set, Instantiating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=20)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "trees = RandomForestClassifier(min_samples_leaf=20)\n",
    "trees.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trees.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While my correctly classified good cars is really low, I know that the competition is using a loss function that grades the probability of being predicted a bad car for each ID rather than correctly put it in the right class. Using a size of 20 was the first size that correctly predicted some of the cars to be a purchase. I tried some other leaf parameters, but found 20 to be my best one for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93     19211\n",
      "           1       1.00      0.00      0.00      2684\n",
      "\n",
      "    accuracy                           0.88     21895\n",
      "   macro avg       0.94      0.50      0.47     21895\n",
      "weighted avg       0.89      0.88      0.82     21895\n",
      "\n",
      "[[19211     0]\n",
      " [ 2680     4]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.47875282e-02, 1.49329959e-02, 1.06282663e-02, 1.34616302e-02,\n",
       "       7.45889001e-03, 1.76376449e-03, 9.50527534e-03, 6.29436408e-03,\n",
       "       6.07496352e-03, 1.07328361e-02, 1.41873266e-03, 2.16996597e-03,\n",
       "       1.42468889e-03, 2.81242763e-03, 3.12151407e-05, 2.79456976e-03,\n",
       "       2.37691837e-03, 1.61623336e-03, 8.32227591e-04, 2.09350856e-03,\n",
       "       2.53273159e-03, 1.03115089e-01, 1.18687758e-01, 1.23948917e-01,\n",
       "       9.91203200e-02, 1.18831332e-01, 1.04484206e-01, 7.38702040e-02,\n",
       "       7.21984402e-02])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VehYear</td>\n",
       "      <td>0.084788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PurchDate</td>\n",
       "      <td>0.014933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auction_ADESA</td>\n",
       "      <td>0.010628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auction_MANHEIM</td>\n",
       "      <td>0.013462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auction_OTHER</td>\n",
       "      <td>0.007459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>generalMake_AMERICAN</td>\n",
       "      <td>0.001764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>generalMake_CHEVROLET</td>\n",
       "      <td>0.009505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>generalMake_CHRYSLER</td>\n",
       "      <td>0.006294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>generalMake_DODGE</td>\n",
       "      <td>0.006075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>generalMake_FORD</td>\n",
       "      <td>0.010733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>generalMake_HYUNDAI</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>generalMake_JEEP</td>\n",
       "      <td>0.002170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>generalMake_KIA</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>generalMake_NISSAN</td>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>generalMake_OTHER</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>generalMake_OTHER ASIAN</td>\n",
       "      <td>0.002795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>generalMake_PONTIAC</td>\n",
       "      <td>0.002377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>generalMake_SATURN</td>\n",
       "      <td>0.001616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>generalMake_TOP LINE ASIAN</td>\n",
       "      <td>0.000832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Transmission_AUTO</td>\n",
       "      <td>0.002094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Transmission_MANUAL</td>\n",
       "      <td>0.002533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VehOdo</td>\n",
       "      <td>0.103115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VehBCost</td>\n",
       "      <td>0.118688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MMRAcqAucAvg</td>\n",
       "      <td>0.123949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MMRAcqRetAvg</td>\n",
       "      <td>0.099120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MMRCurrAucAvg</td>\n",
       "      <td>0.118831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MMRCurrRetAvg</td>\n",
       "      <td>0.104484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WarrantyCost</td>\n",
       "      <td>0.073870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BYRNO</td>\n",
       "      <td>0.072198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Features  Importance\n",
       "0                      VehYear    0.084788\n",
       "1                    PurchDate    0.014933\n",
       "2                Auction_ADESA    0.010628\n",
       "3              Auction_MANHEIM    0.013462\n",
       "4                Auction_OTHER    0.007459\n",
       "5         generalMake_AMERICAN    0.001764\n",
       "6        generalMake_CHEVROLET    0.009505\n",
       "7         generalMake_CHRYSLER    0.006294\n",
       "8            generalMake_DODGE    0.006075\n",
       "9             generalMake_FORD    0.010733\n",
       "10         generalMake_HYUNDAI    0.001419\n",
       "11            generalMake_JEEP    0.002170\n",
       "12             generalMake_KIA    0.001425\n",
       "13          generalMake_NISSAN    0.002812\n",
       "14           generalMake_OTHER    0.000031\n",
       "15     generalMake_OTHER ASIAN    0.002795\n",
       "16         generalMake_PONTIAC    0.002377\n",
       "17          generalMake_SATURN    0.001616\n",
       "18  generalMake_TOP LINE ASIAN    0.000832\n",
       "19           Transmission_AUTO    0.002094\n",
       "20         Transmission_MANUAL    0.002533\n",
       "21                      VehOdo    0.103115\n",
       "22                    VehBCost    0.118688\n",
       "23                MMRAcqAucAvg    0.123949\n",
       "24                MMRAcqRetAvg    0.099120\n",
       "25               MMRCurrAucAvg    0.118831\n",
       "26               MMRCurrRetAvg    0.104484\n",
       "27                WarrantyCost    0.073870\n",
       "28                       BYRNO    0.072198"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some ending EDA where we find that the vehicle year is the most important features in determining if a car will be a good\n",
    "#buy is VehBCost, MMRCurrAucAvg, and MMRAcqAucAvg\n",
    "importantfeatures = pd.DataFrame({\"Features\":X.columns,\"Importance\":trees.feature_importances_})\n",
    "importantfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds = trees.predict_proba(test.drop(\"RefId\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90075489, 0.90724796, 0.92682533, ..., 0.89602348, 0.8531159 ,\n",
       "       0.77138744])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpreds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\"RefId\": test.RefId, \"IsBadBuy\":testpreds[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>IsBadBuy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73015</td>\n",
       "      <td>0.099245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73016</td>\n",
       "      <td>0.092752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73017</td>\n",
       "      <td>0.073175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73018</td>\n",
       "      <td>0.280980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73019</td>\n",
       "      <td>0.229635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RefId  IsBadBuy\n",
       "0  73015  0.099245\n",
       "1  73016  0.092752\n",
       "2  73017  0.073175\n",
       "3  73018  0.280980\n",
       "4  73019  0.229635"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"pysubmission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the model that gave me the best results in the kaggle competition. The random forest classifier outperformed both my Adaboost model and my Neural Network, which are included below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(learning_rate=.1)\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpreds = ada.predict_proba(test.drop(\"RefId\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59263502, 0.40736498],\n",
       "       [0.59577437, 0.40422563],\n",
       "       [0.61586983, 0.38413017],\n",
       "       ...,\n",
       "       [0.60893215, 0.39106785],\n",
       "       [0.59674858, 0.40325142],\n",
       "       [0.57926244, 0.42073756]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = pd.DataFrame({\"RefId\": test.RefId, \"IsBadBuy\":testpreds[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2.to_csv(\"pysubmission2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldX_train = X_train.copy()\n",
    "oldX_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=28,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=20,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=10,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.4021 - accuracy: 0.8746 - val_loss: 0.3592 - val_accuracy: 0.8774\n",
      "Epoch 2/600\n",
      "1597/1597 [==============================] - 1s 935us/step - loss: 0.3728 - accuracy: 0.8768 - val_loss: 0.3588 - val_accuracy: 0.8774\n",
      "Epoch 3/600\n",
      "1597/1597 [==============================] - 1s 926us/step - loss: 0.3666 - accuracy: 0.8768 - val_loss: 0.3578 - val_accuracy: 0.8774\n",
      "Epoch 4/600\n",
      "1597/1597 [==============================] - 1s 911us/step - loss: 0.3644 - accuracy: 0.8768 - val_loss: 0.3562 - val_accuracy: 0.8774\n",
      "Epoch 5/600\n",
      "1597/1597 [==============================] - 1s 920us/step - loss: 0.3626 - accuracy: 0.8768 - val_loss: 0.3569 - val_accuracy: 0.8774\n",
      "Epoch 6/600\n",
      "1597/1597 [==============================] - 1s 934us/step - loss: 0.3610 - accuracy: 0.8768 - val_loss: 0.3554 - val_accuracy: 0.8774\n",
      "Epoch 7/600\n",
      "1597/1597 [==============================] - 2s 949us/step - loss: 0.3592 - accuracy: 0.8768 - val_loss: 0.3554 - val_accuracy: 0.8774\n",
      "Epoch 8/600\n",
      "1597/1597 [==============================] - 2s 974us/step - loss: 0.3597 - accuracy: 0.8768 - val_loss: 0.3559 - val_accuracy: 0.8774\n",
      "Epoch 9/600\n",
      "1597/1597 [==============================] - 1s 902us/step - loss: 0.3592 - accuracy: 0.8767 - val_loss: 0.3563 - val_accuracy: 0.8774\n",
      "Epoch 10/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3589 - accuracy: 0.8768 - val_loss: 0.3555 - val_accuracy: 0.8774\n",
      "Epoch 11/600\n",
      "1597/1597 [==============================] - 1s 899us/step - loss: 0.3583 - accuracy: 0.8767 - val_loss: 0.3552 - val_accuracy: 0.8774\n",
      "Epoch 12/600\n",
      "1597/1597 [==============================] - 1s 937us/step - loss: 0.3584 - accuracy: 0.8768 - val_loss: 0.3554 - val_accuracy: 0.8774\n",
      "Epoch 13/600\n",
      "1597/1597 [==============================] - 1s 913us/step - loss: 0.3589 - accuracy: 0.8767 - val_loss: 0.3552 - val_accuracy: 0.8774\n",
      "Epoch 14/600\n",
      "1597/1597 [==============================] - 1s 895us/step - loss: 0.3584 - accuracy: 0.8768 - val_loss: 0.3554 - val_accuracy: 0.8774\n",
      "Epoch 15/600\n",
      "1597/1597 [==============================] - 1s 922us/step - loss: 0.3579 - accuracy: 0.8767 - val_loss: 0.3552 - val_accuracy: 0.8774\n",
      "Epoch 16/600\n",
      "1597/1597 [==============================] - 1s 908us/step - loss: 0.3575 - accuracy: 0.8768 - val_loss: 0.3557 - val_accuracy: 0.8774\n",
      "Epoch 17/600\n",
      "1597/1597 [==============================] - 1s 917us/step - loss: 0.3580 - accuracy: 0.8768 - val_loss: 0.3550 - val_accuracy: 0.8774\n",
      "Epoch 18/600\n",
      "1597/1597 [==============================] - 1s 907us/step - loss: 0.3569 - accuracy: 0.8767 - val_loss: 0.3554 - val_accuracy: 0.8774\n",
      "Epoch 19/600\n",
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3577 - accuracy: 0.8767 - val_loss: 0.3546 - val_accuracy: 0.8774\n",
      "Epoch 20/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3576 - accuracy: 0.8768 - val_loss: 0.3551 - val_accuracy: 0.8774\n",
      "Epoch 21/600\n",
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3576 - accuracy: 0.8768 - val_loss: 0.3545 - val_accuracy: 0.8774\n",
      "Epoch 22/600\n",
      "1597/1597 [==============================] - 1s 916us/step - loss: 0.3570 - accuracy: 0.8767 - val_loss: 0.3550 - val_accuracy: 0.8774\n",
      "Epoch 23/600\n",
      "1597/1597 [==============================] - 1s 904us/step - loss: 0.3571 - accuracy: 0.8767 - val_loss: 0.3552 - val_accuracy: 0.8774\n",
      "Epoch 24/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3569 - accuracy: 0.8768 - val_loss: 0.3542 - val_accuracy: 0.8774\n",
      "Epoch 25/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3567 - accuracy: 0.8767 - val_loss: 0.3558 - val_accuracy: 0.8774\n",
      "Epoch 26/600\n",
      "1597/1597 [==============================] - 1s 908us/step - loss: 0.3562 - accuracy: 0.8768 - val_loss: 0.3549 - val_accuracy: 0.8774\n",
      "Epoch 27/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3560 - accuracy: 0.8767 - val_loss: 0.3559 - val_accuracy: 0.8774\n",
      "Epoch 28/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3560 - accuracy: 0.8768 - val_loss: 0.3542 - val_accuracy: 0.8774\n",
      "Epoch 29/600\n",
      "1597/1597 [==============================] - 1s 904us/step - loss: 0.3569 - accuracy: 0.8768 - val_loss: 0.3552 - val_accuracy: 0.8774\n",
      "Epoch 30/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3563 - accuracy: 0.8767 - val_loss: 0.3552 - val_accuracy: 0.8774\n",
      "Epoch 31/600\n",
      "1597/1597 [==============================] - 1s 906us/step - loss: 0.3567 - accuracy: 0.8766 - val_loss: 0.3544 - val_accuracy: 0.8774\n",
      "Epoch 32/600\n",
      "1597/1597 [==============================] - 1s 893us/step - loss: 0.3559 - accuracy: 0.8768 - val_loss: 0.3546 - val_accuracy: 0.8774\n",
      "Epoch 33/600\n",
      "1597/1597 [==============================] - 1s 896us/step - loss: 0.3563 - accuracy: 0.8769 - val_loss: 0.3544 - val_accuracy: 0.8774\n",
      "Epoch 34/600\n",
      "1597/1597 [==============================] - 1s 899us/step - loss: 0.3567 - accuracy: 0.8766 - val_loss: 0.3540 - val_accuracy: 0.8774\n",
      "Epoch 35/600\n",
      "1597/1597 [==============================] - 1s 906us/step - loss: 0.3565 - accuracy: 0.8768 - val_loss: 0.3543 - val_accuracy: 0.8774\n",
      "Epoch 36/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3568 - accuracy: 0.8767 - val_loss: 0.3545 - val_accuracy: 0.8774\n",
      "Epoch 37/600\n",
      "1597/1597 [==============================] - 1s 895us/step - loss: 0.3559 - accuracy: 0.8768 - val_loss: 0.3539 - val_accuracy: 0.8774\n",
      "Epoch 38/600\n",
      "1597/1597 [==============================] - 1s 906us/step - loss: 0.3568 - accuracy: 0.8770 - val_loss: 0.3555 - val_accuracy: 0.8774\n",
      "Epoch 39/600\n",
      "1597/1597 [==============================] - 1s 905us/step - loss: 0.3557 - accuracy: 0.8768 - val_loss: 0.3539 - val_accuracy: 0.8774\n",
      "Epoch 40/600\n",
      "1597/1597 [==============================] - 1s 921us/step - loss: 0.3563 - accuracy: 0.8767 - val_loss: 0.3541 - val_accuracy: 0.8774\n",
      "Epoch 41/600\n",
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3558 - accuracy: 0.8766 - val_loss: 0.3542 - val_accuracy: 0.8774\n",
      "Epoch 42/600\n",
      "1597/1597 [==============================] - 1s 906us/step - loss: 0.3560 - accuracy: 0.8769 - val_loss: 0.3543 - val_accuracy: 0.8774\n",
      "Epoch 43/600\n",
      "1597/1597 [==============================] - 1s 917us/step - loss: 0.3566 - accuracy: 0.8767 - val_loss: 0.3538 - val_accuracy: 0.8774\n",
      "Epoch 44/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3562 - accuracy: 0.8767 - val_loss: 0.3553 - val_accuracy: 0.8774\n",
      "Epoch 45/600\n",
      "1597/1597 [==============================] - 1s 905us/step - loss: 0.3551 - accuracy: 0.8768 - val_loss: 0.3558 - val_accuracy: 0.8774\n",
      "Epoch 46/600\n",
      "1597/1597 [==============================] - 1s 921us/step - loss: 0.3560 - accuracy: 0.8767 - val_loss: 0.3545 - val_accuracy: 0.8774\n",
      "Epoch 47/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3555 - accuracy: 0.8768 - val_loss: 0.3539 - val_accuracy: 0.8774\n",
      "Epoch 48/600\n",
      "1597/1597 [==============================] - 1s 915us/step - loss: 0.3555 - accuracy: 0.8767 - val_loss: 0.3540 - val_accuracy: 0.8774\n",
      "Epoch 49/600\n",
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3557 - accuracy: 0.8767 - val_loss: 0.3535 - val_accuracy: 0.8774\n",
      "Epoch 50/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3557 - accuracy: 0.8766 - val_loss: 0.3546 - val_accuracy: 0.8774\n",
      "Epoch 51/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3559 - accuracy: 0.8766 - val_loss: 0.3547 - val_accuracy: 0.8774\n",
      "Epoch 52/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3557 - accuracy: 0.8767 - val_loss: 0.3548 - val_accuracy: 0.8774\n",
      "Epoch 53/600\n",
      "1597/1597 [==============================] - 1s 910us/step - loss: 0.3552 - accuracy: 0.8767 - val_loss: 0.3544 - val_accuracy: 0.8774\n",
      "Epoch 54/600\n",
      "1597/1597 [==============================] - 1s 904us/step - loss: 0.3560 - accuracy: 0.8765 - val_loss: 0.3543 - val_accuracy: 0.8774\n",
      "Epoch 55/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3554 - accuracy: 0.8767 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 56/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 1s 918us/step - loss: 0.3556 - accuracy: 0.8768 - val_loss: 0.3535 - val_accuracy: 0.8774\n",
      "Epoch 57/600\n",
      "1597/1597 [==============================] - 1s 906us/step - loss: 0.3558 - accuracy: 0.8767 - val_loss: 0.3540 - val_accuracy: 0.8774\n",
      "Epoch 58/600\n",
      "1597/1597 [==============================] - 1s 912us/step - loss: 0.3549 - accuracy: 0.8767 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 59/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3552 - accuracy: 0.8766 - val_loss: 0.3545 - val_accuracy: 0.8774\n",
      "Epoch 60/600\n",
      "1597/1597 [==============================] - 1s 908us/step - loss: 0.3552 - accuracy: 0.8764 - val_loss: 0.3542 - val_accuracy: 0.8774\n",
      "Epoch 61/600\n",
      "1597/1597 [==============================] - 1s 909us/step - loss: 0.3551 - accuracy: 0.8766 - val_loss: 0.3536 - val_accuracy: 0.8774\n",
      "Epoch 62/600\n",
      "1597/1597 [==============================] - 1s 893us/step - loss: 0.3549 - accuracy: 0.8768 - val_loss: 0.3540 - val_accuracy: 0.8774\n",
      "Epoch 63/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3550 - accuracy: 0.8766 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 64/600\n",
      "1597/1597 [==============================] - 1s 904us/step - loss: 0.3549 - accuracy: 0.8768 - val_loss: 0.3537 - val_accuracy: 0.8774\n",
      "Epoch 65/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3549 - accuracy: 0.8767 - val_loss: 0.3535 - val_accuracy: 0.8774\n",
      "Epoch 66/600\n",
      "1597/1597 [==============================] - 1s 909us/step - loss: 0.3558 - accuracy: 0.8766 - val_loss: 0.3548 - val_accuracy: 0.8774\n",
      "Epoch 67/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3550 - accuracy: 0.8767 - val_loss: 0.3543 - val_accuracy: 0.8774\n",
      "Epoch 68/600\n",
      "1597/1597 [==============================] - 1s 926us/step - loss: 0.3549 - accuracy: 0.8768 - val_loss: 0.3543 - val_accuracy: 0.8774\n",
      "Epoch 69/600\n",
      "1597/1597 [==============================] - 2s 940us/step - loss: 0.3552 - accuracy: 0.8767 - val_loss: 0.3540 - val_accuracy: 0.8774\n",
      "Epoch 70/600\n",
      "1597/1597 [==============================] - 2s 953us/step - loss: 0.3550 - accuracy: 0.8766 - val_loss: 0.3540 - val_accuracy: 0.8774\n",
      "Epoch 71/600\n",
      "1597/1597 [==============================] - 2s 943us/step - loss: 0.3545 - accuracy: 0.8768 - val_loss: 0.3541 - val_accuracy: 0.8774\n",
      "Epoch 72/600\n",
      "1597/1597 [==============================] - 1s 933us/step - loss: 0.3551 - accuracy: 0.8767 - val_loss: 0.3542 - val_accuracy: 0.8774\n",
      "Epoch 73/600\n",
      "1597/1597 [==============================] - 1s 935us/step - loss: 0.3551 - accuracy: 0.8766 - val_loss: 0.3536 - val_accuracy: 0.8774\n",
      "Epoch 74/600\n",
      "1597/1597 [==============================] - 1s 905us/step - loss: 0.3549 - accuracy: 0.8766 - val_loss: 0.3544 - val_accuracy: 0.8774\n",
      "Epoch 75/600\n",
      "1597/1597 [==============================] - 1s 906us/step - loss: 0.3541 - accuracy: 0.8769 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 76/600\n",
      "1597/1597 [==============================] - 1s 900us/step - loss: 0.3556 - accuracy: 0.8765 - val_loss: 0.3535 - val_accuracy: 0.8774\n",
      "Epoch 77/600\n",
      "1597/1597 [==============================] - 1s 912us/step - loss: 0.3549 - accuracy: 0.8767 - val_loss: 0.3536 - val_accuracy: 0.8774\n",
      "Epoch 78/600\n",
      "1597/1597 [==============================] - 2s 961us/step - loss: 0.3542 - accuracy: 0.8767 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 79/600\n",
      "1597/1597 [==============================] - 2s 942us/step - loss: 0.3546 - accuracy: 0.8769 - val_loss: 0.3536 - val_accuracy: 0.8774\n",
      "Epoch 80/600\n",
      "1597/1597 [==============================] - 1s 921us/step - loss: 0.3553 - accuracy: 0.8766 - val_loss: 0.3537 - val_accuracy: 0.8774\n",
      "Epoch 81/600\n",
      "1597/1597 [==============================] - 1s 921us/step - loss: 0.3549 - accuracy: 0.8767 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 82/600\n",
      "1597/1597 [==============================] - 1s 929us/step - loss: 0.3547 - accuracy: 0.8767 - val_loss: 0.3544 - val_accuracy: 0.8774\n",
      "Epoch 83/600\n",
      "1597/1597 [==============================] - 1s 928us/step - loss: 0.3539 - accuracy: 0.8767 - val_loss: 0.3537 - val_accuracy: 0.8774\n",
      "Epoch 84/600\n",
      "1597/1597 [==============================] - 1s 909us/step - loss: 0.3543 - accuracy: 0.8768 - val_loss: 0.3530 - val_accuracy: 0.8774\n",
      "Epoch 85/600\n",
      "1597/1597 [==============================] - 1s 908us/step - loss: 0.3546 - accuracy: 0.8765 - val_loss: 0.3535 - val_accuracy: 0.8774\n",
      "Epoch 86/600\n",
      "1597/1597 [==============================] - 1s 918us/step - loss: 0.3546 - accuracy: 0.8769 - val_loss: 0.3530 - val_accuracy: 0.8774\n",
      "Epoch 87/600\n",
      "1597/1597 [==============================] - 2s 960us/step - loss: 0.3551 - accuracy: 0.8767 - val_loss: 0.3539 - val_accuracy: 0.8774\n",
      "Epoch 88/600\n",
      "1597/1597 [==============================] - 1s 912us/step - loss: 0.3546 - accuracy: 0.8766 - val_loss: 0.3535 - val_accuracy: 0.8774\n",
      "Epoch 89/600\n",
      "1597/1597 [==============================] - 1s 898us/step - loss: 0.3541 - accuracy: 0.8768 - val_loss: 0.3538 - val_accuracy: 0.8774\n",
      "Epoch 90/600\n",
      "1597/1597 [==============================] - 1s 900us/step - loss: 0.3546 - accuracy: 0.8767 - val_loss: 0.3537 - val_accuracy: 0.8774\n",
      "Epoch 91/600\n",
      "1597/1597 [==============================] - 1s 908us/step - loss: 0.3546 - accuracy: 0.8769 - val_loss: 0.3531 - val_accuracy: 0.8774\n",
      "Epoch 92/600\n",
      "1597/1597 [==============================] - 1s 908us/step - loss: 0.3545 - accuracy: 0.8768 - val_loss: 0.3538 - val_accuracy: 0.8774\n",
      "Epoch 93/600\n",
      "1597/1597 [==============================] - 1s 921us/step - loss: 0.3546 - accuracy: 0.8766 - val_loss: 0.3533 - val_accuracy: 0.8774\n",
      "Epoch 94/600\n",
      "1597/1597 [==============================] - 1s 909us/step - loss: 0.3550 - accuracy: 0.8770 - val_loss: 0.3530 - val_accuracy: 0.8774\n",
      "Epoch 95/600\n",
      "1597/1597 [==============================] - 1s 904us/step - loss: 0.3541 - accuracy: 0.8768 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 96/600\n",
      "1597/1597 [==============================] - 2s 950us/step - loss: 0.3540 - accuracy: 0.8767 - val_loss: 0.3527 - val_accuracy: 0.8774\n",
      "Epoch 97/600\n",
      "1597/1597 [==============================] - 2s 985us/step - loss: 0.3547 - accuracy: 0.8765 - val_loss: 0.3533 - val_accuracy: 0.8774\n",
      "Epoch 98/600\n",
      "1597/1597 [==============================] - 2s 991us/step - loss: 0.3550 - accuracy: 0.8767 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 99/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3538 - accuracy: 0.8767 - val_loss: 0.3531 - val_accuracy: 0.8774\n",
      "Epoch 100/600\n",
      "1597/1597 [==============================] - 2s 977us/step - loss: 0.3546 - accuracy: 0.8768 - val_loss: 0.3531 - val_accuracy: 0.8774\n",
      "Epoch 101/600\n",
      "1597/1597 [==============================] - 2s 960us/step - loss: 0.3543 - accuracy: 0.8767 - val_loss: 0.3533 - val_accuracy: 0.8774\n",
      "Epoch 102/600\n",
      "1597/1597 [==============================] - 2s 981us/step - loss: 0.3539 - accuracy: 0.8767 - val_loss: 0.3540 - val_accuracy: 0.8774\n",
      "Epoch 103/600\n",
      "1597/1597 [==============================] - 2s 995us/step - loss: 0.3547 - accuracy: 0.8767 - val_loss: 0.3533 - val_accuracy: 0.8774\n",
      "Epoch 104/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3549 - accuracy: 0.8768 - val_loss: 0.3535 - val_accuracy: 0.8774\n",
      "Epoch 105/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3542 - accuracy: 0.8767 - val_loss: 0.3531 - val_accuracy: 0.8774\n",
      "Epoch 106/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3545 - accuracy: 0.8766 - val_loss: 0.3544 - val_accuracy: 0.8774\n",
      "Epoch 107/600\n",
      "1597/1597 [==============================] - 1s 919us/step - loss: 0.3544 - accuracy: 0.8767 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 108/600\n",
      "1597/1597 [==============================] - 2s 942us/step - loss: 0.3544 - accuracy: 0.8767 - val_loss: 0.3533 - val_accuracy: 0.8774\n",
      "Epoch 109/600\n",
      "1597/1597 [==============================] - 2s 959us/step - loss: 0.3543 - accuracy: 0.8766 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 110/600\n",
      "1597/1597 [==============================] - 2s 961us/step - loss: 0.3535 - accuracy: 0.8767 - val_loss: 0.3526 - val_accuracy: 0.8774\n",
      "Epoch 111/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3537 - accuracy: 0.8767 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 112/600\n",
      "1597/1597 [==============================] - 2s 956us/step - loss: 0.3538 - accuracy: 0.8767 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 113/600\n",
      "1597/1597 [==============================] - 2s 945us/step - loss: 0.3545 - accuracy: 0.8766 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 114/600\n",
      "1597/1597 [==============================] - 2s 971us/step - loss: 0.3541 - accuracy: 0.8768 - val_loss: 0.3529 - val_accuracy: 0.8774\n",
      "Epoch 115/600\n",
      "1597/1597 [==============================] - 2s 990us/step - loss: 0.3541 - accuracy: 0.8767 - val_loss: 0.3533 - val_accuracy: 0.8774\n",
      "Epoch 116/600\n",
      "1597/1597 [==============================] - 2s 979us/step - loss: 0.3538 - accuracy: 0.8766 - val_loss: 0.3529 - val_accuracy: 0.8774\n",
      "Epoch 117/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3537 - accuracy: 0.8766 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 118/600\n",
      "1597/1597 [==============================] - 1s 923us/step - loss: 0.3537 - accuracy: 0.8767 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 119/600\n",
      "1597/1597 [==============================] - 1s 923us/step - loss: 0.3542 - accuracy: 0.8767 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 120/600\n",
      "1597/1597 [==============================] - 1s 902us/step - loss: 0.3545 - accuracy: 0.8767 - val_loss: 0.3537 - val_accuracy: 0.8774\n",
      "Epoch 121/600\n",
      "1597/1597 [==============================] - 2s 984us/step - loss: 0.3537 - accuracy: 0.8767 - val_loss: 0.3544 - val_accuracy: 0.8774\n",
      "Epoch 122/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3540 - accuracy: 0.8768 - val_loss: 0.3537 - val_accuracy: 0.8774\n",
      "Epoch 123/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3534 - accuracy: 0.8765 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 124/600\n",
      "1597/1597 [==============================] - 2s 969us/step - loss: 0.3540 - accuracy: 0.8768 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 125/600\n",
      "1597/1597 [==============================] - 1s 922us/step - loss: 0.3540 - accuracy: 0.8765 - val_loss: 0.3530 - val_accuracy: 0.8774\n",
      "Epoch 126/600\n",
      "1597/1597 [==============================] - 1s 906us/step - loss: 0.3542 - accuracy: 0.8767 - val_loss: 0.3539 - val_accuracy: 0.8774\n",
      "Epoch 127/600\n",
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3532 - accuracy: 0.8766 - val_loss: 0.3541 - val_accuracy: 0.8774\n",
      "Epoch 128/600\n",
      "1597/1597 [==============================] - 1s 898us/step - loss: 0.3532 - accuracy: 0.8768 - val_loss: 0.3547 - val_accuracy: 0.8774\n",
      "Epoch 129/600\n",
      "1597/1597 [==============================] - 2s 959us/step - loss: 0.3531 - accuracy: 0.8769 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 130/600\n",
      "1597/1597 [==============================] - 1s 928us/step - loss: 0.3541 - accuracy: 0.8769 - val_loss: 0.3538 - val_accuracy: 0.8774\n",
      "Epoch 131/600\n",
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3530 - accuracy: 0.8765 - val_loss: 0.3542 - val_accuracy: 0.8774\n",
      "Epoch 132/600\n",
      "1597/1597 [==============================] - 1s 895us/step - loss: 0.3535 - accuracy: 0.8769 - val_loss: 0.3527 - val_accuracy: 0.8774\n",
      "Epoch 133/600\n",
      "1597/1597 [==============================] - 1s 900us/step - loss: 0.3533 - accuracy: 0.8768 - val_loss: 0.3536 - val_accuracy: 0.8774\n",
      "Epoch 134/600\n",
      "1597/1597 [==============================] - 1s 901us/step - loss: 0.3539 - accuracy: 0.8767 - val_loss: 0.3547 - val_accuracy: 0.8774\n",
      "Epoch 135/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3550 - accuracy: 0.8768 - val_loss: 0.3546 - val_accuracy: 0.8774\n",
      "Epoch 136/600\n",
      "1597/1597 [==============================] - 1s 893us/step - loss: 0.3538 - accuracy: 0.8768 - val_loss: 0.3549 - val_accuracy: 0.8774\n",
      "Epoch 137/600\n",
      "1597/1597 [==============================] - 1s 925us/step - loss: 0.3536 - accuracy: 0.8770 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 138/600\n",
      "1597/1597 [==============================] - 1s 937us/step - loss: 0.3536 - accuracy: 0.8768 - val_loss: 0.3528 - val_accuracy: 0.8774\n",
      "Epoch 139/600\n",
      "1597/1597 [==============================] - 2s 946us/step - loss: 0.3536 - accuracy: 0.8768 - val_loss: 0.3526 - val_accuracy: 0.8774\n",
      "Epoch 140/600\n",
      "1597/1597 [==============================] - 2s 987us/step - loss: 0.3540 - accuracy: 0.8766 - val_loss: 0.3530 - val_accuracy: 0.8774\n",
      "Epoch 141/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3532 - accuracy: 0.8767 - val_loss: 0.3535 - val_accuracy: 0.8774\n",
      "Epoch 142/600\n",
      "1597/1597 [==============================] - 2s 968us/step - loss: 0.3535 - accuracy: 0.8768 - val_loss: 0.3533 - val_accuracy: 0.8774\n",
      "Epoch 143/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3535 - accuracy: 0.8767 - val_loss: 0.3528 - val_accuracy: 0.8774\n",
      "Epoch 144/600\n",
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3531 - accuracy: 0.8767 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 145/600\n",
      "1597/1597 [==============================] - 1s 902us/step - loss: 0.3541 - accuracy: 0.8768 - val_loss: 0.3527 - val_accuracy: 0.8774\n",
      "Epoch 146/600\n",
      "1597/1597 [==============================] - 1s 899us/step - loss: 0.3534 - accuracy: 0.8768 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 147/600\n",
      "1597/1597 [==============================] - 1s 900us/step - loss: 0.3536 - accuracy: 0.8768 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 148/600\n",
      "1597/1597 [==============================] - 1s 893us/step - loss: 0.3532 - accuracy: 0.8767 - val_loss: 0.3530 - val_accuracy: 0.8774\n",
      "Epoch 149/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3533 - accuracy: 0.8766 - val_loss: 0.3531 - val_accuracy: 0.8774\n",
      "Epoch 150/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3532 - accuracy: 0.8765 - val_loss: 0.3519 - val_accuracy: 0.8774\n",
      "Epoch 151/600\n",
      "1597/1597 [==============================] - 1s 893us/step - loss: 0.3535 - accuracy: 0.8767 - val_loss: 0.3535 - val_accuracy: 0.8774\n",
      "Epoch 152/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3531 - accuracy: 0.8766 - val_loss: 0.3542 - val_accuracy: 0.8774\n",
      "Epoch 153/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3532 - accuracy: 0.8769 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 154/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3528 - accuracy: 0.8768 - val_loss: 0.3541 - val_accuracy: 0.8774\n",
      "Epoch 155/600\n",
      "1597/1597 [==============================] - 1s 898us/step - loss: 0.3529 - accuracy: 0.8767 - val_loss: 0.3539 - val_accuracy: 0.8774\n",
      "Epoch 156/600\n",
      "1597/1597 [==============================] - 1s 893us/step - loss: 0.3526 - accuracy: 0.8768 - val_loss: 0.3541 - val_accuracy: 0.8774\n",
      "Epoch 157/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3535 - accuracy: 0.8764 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 158/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3535 - accuracy: 0.8768 - val_loss: 0.3527 - val_accuracy: 0.8774\n",
      "Epoch 159/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3531 - accuracy: 0.8768 - val_loss: 0.3537 - val_accuracy: 0.8774\n",
      "Epoch 160/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3538 - accuracy: 0.8767 - val_loss: 0.3525 - val_accuracy: 0.8774\n",
      "Epoch 161/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3533 - accuracy: 0.8767 - val_loss: 0.3536 - val_accuracy: 0.8774\n",
      "Epoch 162/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3535 - accuracy: 0.8765 - val_loss: 0.3533 - val_accuracy: 0.8774\n",
      "Epoch 163/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3529 - accuracy: 0.8768 - val_loss: 0.3538 - val_accuracy: 0.8774\n",
      "Epoch 164/600\n",
      "1597/1597 [==============================] - 1s 896us/step - loss: 0.3531 - accuracy: 0.8770 - val_loss: 0.3528 - val_accuracy: 0.8774\n",
      "Epoch 165/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3532 - accuracy: 0.8766 - val_loss: 0.3538 - val_accuracy: 0.8774\n",
      "Epoch 166/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3536 - accuracy: 0.8768 - val_loss: 0.3528 - val_accuracy: 0.8774\n",
      "Epoch 167/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3530 - accuracy: 0.8767 - val_loss: 0.3531 - val_accuracy: 0.8774\n",
      "Epoch 168/600\n",
      "1597/1597 [==============================] - 1s 899us/step - loss: 0.3533 - accuracy: 0.8766 - val_loss: 0.3525 - val_accuracy: 0.8774\n",
      "Epoch 169/600\n",
      "1597/1597 [==============================] - 1s 896us/step - loss: 0.3533 - accuracy: 0.8767 - val_loss: 0.3531 - val_accuracy: 0.8774\n",
      "Epoch 170/600\n",
      "1597/1597 [==============================] - 1s 885us/step - loss: 0.3531 - accuracy: 0.8767 - val_loss: 0.3529 - val_accuracy: 0.8774\n",
      "Epoch 171/600\n",
      "1597/1597 [==============================] - 1s 884us/step - loss: 0.3538 - accuracy: 0.8766 - val_loss: 0.3533 - val_accuracy: 0.8774\n",
      "Epoch 172/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3532 - accuracy: 0.8766 - val_loss: 0.3527 - val_accuracy: 0.8774\n",
      "Epoch 173/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3537 - accuracy: 0.8766 - val_loss: 0.3529 - val_accuracy: 0.8774\n",
      "Epoch 174/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3523 - accuracy: 0.8768 - val_loss: 0.3527 - val_accuracy: 0.8774\n",
      "Epoch 175/600\n",
      "1597/1597 [==============================] - 1s 895us/step - loss: 0.3525 - accuracy: 0.8768 - val_loss: 0.3538 - val_accuracy: 0.8774\n",
      "Epoch 176/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3531 - accuracy: 0.8767 - val_loss: 0.3531 - val_accuracy: 0.8774\n",
      "Epoch 177/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3534 - accuracy: 0.8767 - val_loss: 0.3531 - val_accuracy: 0.8774\n",
      "Epoch 178/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3531 - accuracy: 0.8767 - val_loss: 0.3527 - val_accuracy: 0.8774\n",
      "Epoch 179/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3531 - accuracy: 0.8766 - val_loss: 0.3535 - val_accuracy: 0.8774\n",
      "Epoch 180/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3531 - accuracy: 0.8766 - val_loss: 0.3537 - val_accuracy: 0.8774\n",
      "Epoch 181/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3534 - accuracy: 0.8769 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 182/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3528 - accuracy: 0.8768 - val_loss: 0.3529 - val_accuracy: 0.8774\n",
      "Epoch 183/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3528 - accuracy: 0.8766 - val_loss: 0.3536 - val_accuracy: 0.8774\n",
      "Epoch 184/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3530 - accuracy: 0.8767 - val_loss: 0.3531 - val_accuracy: 0.8774\n",
      "Epoch 185/600\n",
      "1597/1597 [==============================] - 1s 897us/step - loss: 0.3531 - accuracy: 0.8766 - val_loss: 0.3530 - val_accuracy: 0.8774\n",
      "Epoch 186/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3533 - accuracy: 0.8769 - val_loss: 0.3538 - val_accuracy: 0.8774\n",
      "Epoch 187/600\n",
      "1597/1597 [==============================] - 1s 884us/step - loss: 0.3524 - accuracy: 0.8769 - val_loss: 0.3537 - val_accuracy: 0.8774\n",
      "Epoch 188/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3533 - accuracy: 0.8767 - val_loss: 0.3527 - val_accuracy: 0.8774\n",
      "Epoch 189/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3526 - accuracy: 0.8768 - val_loss: 0.3530 - val_accuracy: 0.8774\n",
      "Epoch 190/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3524 - accuracy: 0.8766 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 191/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3526 - accuracy: 0.8767 - val_loss: 0.3525 - val_accuracy: 0.8774\n",
      "Epoch 192/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3535 - accuracy: 0.8766 - val_loss: 0.3526 - val_accuracy: 0.8774\n",
      "Epoch 193/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3534 - accuracy: 0.8765 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 194/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3530 - accuracy: 0.8764 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 195/600\n",
      "1597/1597 [==============================] - 1s 895us/step - loss: 0.3529 - accuracy: 0.8768 - val_loss: 0.3525 - val_accuracy: 0.8774\n",
      "Epoch 196/600\n",
      "1597/1597 [==============================] - 1s 915us/step - loss: 0.3521 - accuracy: 0.8764 - val_loss: 0.3519 - val_accuracy: 0.8774\n",
      "Epoch 197/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3532 - accuracy: 0.8768 - val_loss: 0.3526 - val_accuracy: 0.8774\n",
      "Epoch 198/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3524 - accuracy: 0.8766 - val_loss: 0.3524 - val_accuracy: 0.8774\n",
      "Epoch 199/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3527 - accuracy: 0.8767 - val_loss: 0.3525 - val_accuracy: 0.8774\n",
      "Epoch 200/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3527 - accuracy: 0.8767 - val_loss: 0.3526 - val_accuracy: 0.8774\n",
      "Epoch 201/600\n",
      "1597/1597 [==============================] - 1s 897us/step - loss: 0.3527 - accuracy: 0.8767 - val_loss: 0.3528 - val_accuracy: 0.8774\n",
      "Epoch 202/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3527 - accuracy: 0.8768 - val_loss: 0.3522 - val_accuracy: 0.8774\n",
      "Epoch 203/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3523 - accuracy: 0.8766 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 204/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3534 - accuracy: 0.8768 - val_loss: 0.3531 - val_accuracy: 0.8775\n",
      "Epoch 205/600\n",
      "1597/1597 [==============================] - 1s 883us/step - loss: 0.3526 - accuracy: 0.8765 - val_loss: 0.3536 - val_accuracy: 0.8774\n",
      "Epoch 206/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3531 - accuracy: 0.8768 - val_loss: 0.3533 - val_accuracy: 0.8774\n",
      "Epoch 207/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3527 - accuracy: 0.8766 - val_loss: 0.3520 - val_accuracy: 0.8774\n",
      "Epoch 208/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3520 - accuracy: 0.8768 - val_loss: 0.3525 - val_accuracy: 0.8774\n",
      "Epoch 209/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3530 - accuracy: 0.8766 - val_loss: 0.3528 - val_accuracy: 0.8774\n",
      "Epoch 210/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3526 - accuracy: 0.8769 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 211/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3524 - accuracy: 0.8768 - val_loss: 0.3527 - val_accuracy: 0.8774\n",
      "Epoch 212/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3521 - accuracy: 0.8768 - val_loss: 0.3519 - val_accuracy: 0.8774\n",
      "Epoch 213/600\n",
      "1597/1597 [==============================] - 1s 896us/step - loss: 0.3526 - accuracy: 0.8768 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 214/600\n",
      "1597/1597 [==============================] - 1s 902us/step - loss: 0.3529 - accuracy: 0.8766 - val_loss: 0.3523 - val_accuracy: 0.8774\n",
      "Epoch 215/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3524 - accuracy: 0.8767 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 216/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3529 - accuracy: 0.8768 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 217/600\n",
      "1597/1597 [==============================] - 1s 893us/step - loss: 0.3527 - accuracy: 0.8769 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 218/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3525 - accuracy: 0.8770 - val_loss: 0.3524 - val_accuracy: 0.8774\n",
      "Epoch 219/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3527 - accuracy: 0.8767 - val_loss: 0.3518 - val_accuracy: 0.8774\n",
      "Epoch 220/600\n",
      "1597/1597 [==============================] - 1s 895us/step - loss: 0.3520 - accuracy: 0.8768 - val_loss: 0.3521 - val_accuracy: 0.8774\n",
      "Epoch 221/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 1s 921us/step - loss: 0.3538 - accuracy: 0.8767 - val_loss: 0.3512 - val_accuracy: 0.8774\n",
      "Epoch 222/600\n",
      "1597/1597 [==============================] - 1s 916us/step - loss: 0.3524 - accuracy: 0.8767 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 223/600\n",
      "1597/1597 [==============================] - 1s 893us/step - loss: 0.3525 - accuracy: 0.8766 - val_loss: 0.3513 - val_accuracy: 0.8774\n",
      "Epoch 224/600\n",
      "1597/1597 [==============================] - 1s 898us/step - loss: 0.3532 - accuracy: 0.8766 - val_loss: 0.3524 - val_accuracy: 0.8774\n",
      "Epoch 225/600\n",
      "1597/1597 [==============================] - 1s 899us/step - loss: 0.3529 - accuracy: 0.8767 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 226/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3520 - accuracy: 0.8766 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 227/600\n",
      "1597/1597 [==============================] - 1s 901us/step - loss: 0.3524 - accuracy: 0.8767 - val_loss: 0.3526 - val_accuracy: 0.8774\n",
      "Epoch 228/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3521 - accuracy: 0.8767 - val_loss: 0.3529 - val_accuracy: 0.8774\n",
      "Epoch 229/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3525 - accuracy: 0.8765 - val_loss: 0.3524 - val_accuracy: 0.8774\n",
      "Epoch 230/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3521 - accuracy: 0.8766 - val_loss: 0.3522 - val_accuracy: 0.8774\n",
      "Epoch 231/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3526 - accuracy: 0.8769 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 232/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3516 - accuracy: 0.8769 - val_loss: 0.3533 - val_accuracy: 0.8775\n",
      "Epoch 233/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3519 - accuracy: 0.8765 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 234/600\n",
      "1597/1597 [==============================] - 1s 885us/step - loss: 0.3527 - accuracy: 0.8768 - val_loss: 0.3519 - val_accuracy: 0.8774\n",
      "Epoch 235/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3526 - accuracy: 0.8766 - val_loss: 0.3528 - val_accuracy: 0.8775\n",
      "Epoch 236/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3521 - accuracy: 0.8766 - val_loss: 0.3521 - val_accuracy: 0.8774\n",
      "Epoch 237/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3523 - accuracy: 0.8768 - val_loss: 0.3521 - val_accuracy: 0.8774\n",
      "Epoch 238/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3525 - accuracy: 0.8767 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 239/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3529 - accuracy: 0.8767 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 240/600\n",
      "1597/1597 [==============================] - 1s 884us/step - loss: 0.3526 - accuracy: 0.8768 - val_loss: 0.3534 - val_accuracy: 0.8774\n",
      "Epoch 241/600\n",
      "1597/1597 [==============================] - 1s 884us/step - loss: 0.3528 - accuracy: 0.8767 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 242/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3519 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 243/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3523 - accuracy: 0.8768 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 244/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3520 - accuracy: 0.8767 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 245/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3517 - accuracy: 0.8769 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 246/600\n",
      "1597/1597 [==============================] - 1s 885us/step - loss: 0.3525 - accuracy: 0.8768 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 247/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3522 - accuracy: 0.8766 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 248/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3522 - accuracy: 0.8765 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 249/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3521 - accuracy: 0.8768 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 250/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3528 - accuracy: 0.8765 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 251/600\n",
      "1597/1597 [==============================] - 1s 884us/step - loss: 0.3519 - accuracy: 0.8769 - val_loss: 0.3520 - val_accuracy: 0.8774\n",
      "Epoch 252/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3521 - accuracy: 0.8767 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 253/600\n",
      "1597/1597 [==============================] - 1s 885us/step - loss: 0.3516 - accuracy: 0.8769 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 254/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3527 - accuracy: 0.8768 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 255/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3521 - accuracy: 0.8768 - val_loss: 0.3532 - val_accuracy: 0.8775\n",
      "Epoch 256/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3514 - accuracy: 0.8767 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 257/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3531 - accuracy: 0.8768 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 258/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3520 - accuracy: 0.8768 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 259/600\n",
      "1597/1597 [==============================] - 1s 896us/step - loss: 0.3510 - accuracy: 0.8770 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 260/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3524 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 261/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3523 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 262/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3522 - accuracy: 0.8767 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 263/600\n",
      "1597/1597 [==============================] - 1s 895us/step - loss: 0.3514 - accuracy: 0.8768 - val_loss: 0.3511 - val_accuracy: 0.8774\n",
      "Epoch 264/600\n",
      "1597/1597 [==============================] - 1s 893us/step - loss: 0.3522 - accuracy: 0.8767 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 265/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3524 - accuracy: 0.8767 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 266/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3528 - accuracy: 0.8768 - val_loss: 0.3513 - val_accuracy: 0.8775\n",
      "Epoch 267/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3518 - accuracy: 0.8769 - val_loss: 0.3532 - val_accuracy: 0.8774\n",
      "Epoch 268/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3525 - accuracy: 0.8767 - val_loss: 0.3526 - val_accuracy: 0.8774\n",
      "Epoch 269/600\n",
      "1597/1597 [==============================] - 1s 898us/step - loss: 0.3519 - accuracy: 0.8768 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 270/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3515 - accuracy: 0.8766 - val_loss: 0.3512 - val_accuracy: 0.8774\n",
      "Epoch 271/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3523 - accuracy: 0.8765 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 272/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3526 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 273/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3517 - accuracy: 0.8768 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 274/600\n",
      "1597/1597 [==============================] - 1s 883us/step - loss: 0.3518 - accuracy: 0.8766 - val_loss: 0.3523 - val_accuracy: 0.8774\n",
      "Epoch 275/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3526 - accuracy: 0.8766 - val_loss: 0.3522 - val_accuracy: 0.8774\n",
      "Epoch 276/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3517 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 277/600\n",
      "1597/1597 [==============================] - 1s 884us/step - loss: 0.3520 - accuracy: 0.8767 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 278/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3517 - accuracy: 0.8768 - val_loss: 0.3535 - val_accuracy: 0.8775\n",
      "Epoch 279/600\n",
      "1597/1597 [==============================] - 1s 885us/step - loss: 0.3513 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 280/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3522 - accuracy: 0.8767 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 281/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3518 - accuracy: 0.8766 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 282/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3523 - accuracy: 0.8769 - val_loss: 0.3520 - val_accuracy: 0.8774\n",
      "Epoch 283/600\n",
      "1597/1597 [==============================] - 1s 915us/step - loss: 0.3516 - accuracy: 0.8764 - val_loss: 0.3517 - val_accuracy: 0.8774\n",
      "Epoch 284/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3517 - accuracy: 0.8765 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 285/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3513 - accuracy: 0.8769 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 286/600\n",
      "1597/1597 [==============================] - 1s 923us/step - loss: 0.3519 - accuracy: 0.8767 - val_loss: 0.3529 - val_accuracy: 0.8775\n",
      "Epoch 287/600\n",
      "1597/1597 [==============================] - 1s 909us/step - loss: 0.3524 - accuracy: 0.8766 - val_loss: 0.3537 - val_accuracy: 0.8775\n",
      "Epoch 288/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3521 - accuracy: 0.8769 - val_loss: 0.3534 - val_accuracy: 0.8775\n",
      "Epoch 289/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3523 - accuracy: 0.8769 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 290/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3521 - accuracy: 0.8767 - val_loss: 0.3529 - val_accuracy: 0.8775\n",
      "Epoch 291/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3521 - accuracy: 0.8768 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 292/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3527 - accuracy: 0.8766 - val_loss: 0.3514 - val_accuracy: 0.8775\n",
      "Epoch 293/600\n",
      "1597/1597 [==============================] - 1s 885us/step - loss: 0.3515 - accuracy: 0.8765 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 294/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3516 - accuracy: 0.8765 - val_loss: 0.3514 - val_accuracy: 0.8775\n",
      "Epoch 295/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3519 - accuracy: 0.8766 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 296/600\n",
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3507 - accuracy: 0.8766 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 297/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3512 - accuracy: 0.8767 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 298/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3519 - accuracy: 0.8766 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 299/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3517 - accuracy: 0.8768 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 300/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3521 - accuracy: 0.8767 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 301/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3522 - accuracy: 0.8768 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 302/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3519 - accuracy: 0.8768 - val_loss: 0.3515 - val_accuracy: 0.8775\n",
      "Epoch 303/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3515 - accuracy: 0.8768 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 304/600\n",
      "1597/1597 [==============================] - 1s 906us/step - loss: 0.3519 - accuracy: 0.8767 - val_loss: 0.3528 - val_accuracy: 0.8775\n",
      "Epoch 305/600\n",
      "1597/1597 [==============================] - 1s 916us/step - loss: 0.3520 - accuracy: 0.8765 - val_loss: 0.3515 - val_accuracy: 0.8775\n",
      "Epoch 306/600\n",
      "1597/1597 [==============================] - 1s 912us/step - loss: 0.3522 - accuracy: 0.8767 - val_loss: 0.3515 - val_accuracy: 0.8775\n",
      "Epoch 307/600\n",
      "1597/1597 [==============================] - 1s 910us/step - loss: 0.3517 - accuracy: 0.8769 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 308/600\n",
      "1597/1597 [==============================] - 1s 897us/step - loss: 0.3516 - accuracy: 0.8768 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 309/600\n",
      "1597/1597 [==============================] - 1s 900us/step - loss: 0.3519 - accuracy: 0.8767 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 310/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3521 - accuracy: 0.8769 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 311/600\n",
      "1597/1597 [==============================] - 1s 900us/step - loss: 0.3508 - accuracy: 0.8769 - val_loss: 0.3514 - val_accuracy: 0.8775\n",
      "Epoch 312/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3512 - accuracy: 0.8766 - val_loss: 0.3514 - val_accuracy: 0.8775\n",
      "Epoch 313/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3511 - accuracy: 0.8769 - val_loss: 0.3511 - val_accuracy: 0.8775\n",
      "Epoch 314/600\n",
      "1597/1597 [==============================] - 1s 882us/step - loss: 0.3509 - accuracy: 0.8765 - val_loss: 0.3508 - val_accuracy: 0.8775\n",
      "Epoch 315/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3513 - accuracy: 0.8771 - val_loss: 0.3506 - val_accuracy: 0.8775\n",
      "Epoch 316/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3509 - accuracy: 0.8768 - val_loss: 0.3514 - val_accuracy: 0.8775\n",
      "Epoch 317/600\n",
      "1597/1597 [==============================] - 1s 882us/step - loss: 0.3509 - accuracy: 0.8768 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 318/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3510 - accuracy: 0.8769 - val_loss: 0.3507 - val_accuracy: 0.8775\n",
      "Epoch 319/600\n",
      "1597/1597 [==============================] - 1s 924us/step - loss: 0.3522 - accuracy: 0.8768 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 320/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3509 - accuracy: 0.8768 - val_loss: 0.3515 - val_accuracy: 0.8775\n",
      "Epoch 321/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3517 - accuracy: 0.8767 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 322/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3512 - accuracy: 0.8765 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 323/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3514 - accuracy: 0.8769 - val_loss: 0.3529 - val_accuracy: 0.8775\n",
      "Epoch 324/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3522 - accuracy: 0.8768 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 325/600\n",
      "1597/1597 [==============================] - 1s 885us/step - loss: 0.3518 - accuracy: 0.8768 - val_loss: 0.3515 - val_accuracy: 0.8775\n",
      "Epoch 326/600\n",
      "1597/1597 [==============================] - 1s 883us/step - loss: 0.3518 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 327/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3519 - accuracy: 0.8766 - val_loss: 0.3512 - val_accuracy: 0.8775\n",
      "Epoch 328/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3515 - accuracy: 0.8770 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 329/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3518 - accuracy: 0.8769 - val_loss: 0.3514 - val_accuracy: 0.8775\n",
      "Epoch 330/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3521 - accuracy: 0.8768 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 331/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 1s 890us/step - loss: 0.3512 - accuracy: 0.8768 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 332/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3512 - accuracy: 0.8764 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 333/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3514 - accuracy: 0.8766 - val_loss: 0.3512 - val_accuracy: 0.8775\n",
      "Epoch 334/600\n",
      "1597/1597 [==============================] - 1s 895us/step - loss: 0.3514 - accuracy: 0.8766 - val_loss: 0.3512 - val_accuracy: 0.8775\n",
      "Epoch 335/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3516 - accuracy: 0.8769 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 336/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3513 - accuracy: 0.8768 - val_loss: 0.3510 - val_accuracy: 0.8775\n",
      "Epoch 337/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3518 - accuracy: 0.8766 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 338/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3510 - accuracy: 0.8768 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 339/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3500 - accuracy: 0.8769 - val_loss: 0.3534 - val_accuracy: 0.8775\n",
      "Epoch 340/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3526 - accuracy: 0.8766 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 341/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3505 - accuracy: 0.8766 - val_loss: 0.3515 - val_accuracy: 0.8775\n",
      "Epoch 342/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3513 - accuracy: 0.8766 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 343/600\n",
      "1597/1597 [==============================] - 1s 939us/step - loss: 0.3509 - accuracy: 0.8766 - val_loss: 0.3528 - val_accuracy: 0.8775\n",
      "Epoch 344/600\n",
      "1597/1597 [==============================] - 2s 973us/step - loss: 0.3511 - accuracy: 0.8770 - val_loss: 0.3512 - val_accuracy: 0.8775\n",
      "Epoch 345/600\n",
      "1597/1597 [==============================] - 2s 957us/step - loss: 0.3518 - accuracy: 0.8767 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 346/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3519 - accuracy: 0.8766 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 347/600\n",
      "1597/1597 [==============================] - 2s 951us/step - loss: 0.3514 - accuracy: 0.8769 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 348/600\n",
      "1597/1597 [==============================] - 1s 938us/step - loss: 0.3517 - accuracy: 0.8769 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 349/600\n",
      "1597/1597 [==============================] - 2s 1000us/step - loss: 0.3511 - accuracy: 0.8769 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 350/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3510 - accuracy: 0.8767 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 351/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3520 - accuracy: 0.8767 - val_loss: 0.3515 - val_accuracy: 0.8775\n",
      "Epoch 352/600\n",
      "1597/1597 [==============================] - 1s 926us/step - loss: 0.3515 - accuracy: 0.8767 - val_loss: 0.3508 - val_accuracy: 0.8775\n",
      "Epoch 353/600\n",
      "1597/1597 [==============================] - 1s 919us/step - loss: 0.3516 - accuracy: 0.8770 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 354/600\n",
      "1597/1597 [==============================] - 1s 893us/step - loss: 0.3510 - accuracy: 0.8769 - val_loss: 0.3510 - val_accuracy: 0.8775\n",
      "Epoch 355/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3518 - accuracy: 0.8767 - val_loss: 0.3514 - val_accuracy: 0.8775\n",
      "Epoch 356/600\n",
      "1597/1597 [==============================] - 1s 898us/step - loss: 0.3504 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 357/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3516 - accuracy: 0.8769 - val_loss: 0.3515 - val_accuracy: 0.8775\n",
      "Epoch 358/600\n",
      "1597/1597 [==============================] - 1s 898us/step - loss: 0.3520 - accuracy: 0.8767 - val_loss: 0.3509 - val_accuracy: 0.8775\n",
      "Epoch 359/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3512 - accuracy: 0.8766 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 360/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3516 - accuracy: 0.8765 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 361/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3522 - accuracy: 0.8767 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 362/600\n",
      "1597/1597 [==============================] - 1s 883us/step - loss: 0.3522 - accuracy: 0.8765 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 363/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3515 - accuracy: 0.8767 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 364/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3516 - accuracy: 0.8770 - val_loss: 0.3514 - val_accuracy: 0.8775\n",
      "Epoch 365/600\n",
      "1597/1597 [==============================] - 1s 885us/step - loss: 0.3508 - accuracy: 0.8769 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 366/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3518 - accuracy: 0.8769 - val_loss: 0.3508 - val_accuracy: 0.8775\n",
      "Epoch 367/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3513 - accuracy: 0.8768 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 368/600\n",
      "1597/1597 [==============================] - 1s 886us/step - loss: 0.3514 - accuracy: 0.8766 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 369/600\n",
      "1597/1597 [==============================] - 1s 894us/step - loss: 0.3516 - accuracy: 0.8769 - val_loss: 0.3512 - val_accuracy: 0.8775\n",
      "Epoch 370/600\n",
      "1597/1597 [==============================] - 1s 892us/step - loss: 0.3506 - accuracy: 0.8765 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 371/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3506 - accuracy: 0.8767 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 372/600\n",
      "1597/1597 [==============================] - 1s 913us/step - loss: 0.3512 - accuracy: 0.8767 - val_loss: 0.3512 - val_accuracy: 0.8775\n",
      "Epoch 373/600\n",
      "1597/1597 [==============================] - 2s 954us/step - loss: 0.3517 - accuracy: 0.8766 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 374/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3515 - accuracy: 0.8769 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 375/600\n",
      "1597/1597 [==============================] - 2s 942us/step - loss: 0.3512 - accuracy: 0.8768 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 376/600\n",
      "1597/1597 [==============================] - 1s 922us/step - loss: 0.3516 - accuracy: 0.8767 - val_loss: 0.3507 - val_accuracy: 0.8775\n",
      "Epoch 377/600\n",
      "1597/1597 [==============================] - 1s 925us/step - loss: 0.3502 - accuracy: 0.8768 - val_loss: 0.3507 - val_accuracy: 0.8775\n",
      "Epoch 378/600\n",
      "1597/1597 [==============================] - 1s 931us/step - loss: 0.3508 - accuracy: 0.8770 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 379/600\n",
      "1597/1597 [==============================] - 1s 926us/step - loss: 0.3514 - accuracy: 0.8765 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 380/600\n",
      "1597/1597 [==============================] - 1s 929us/step - loss: 0.3516 - accuracy: 0.8769 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 381/600\n",
      "1597/1597 [==============================] - 1s 891us/step - loss: 0.3517 - accuracy: 0.8767 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 382/600\n",
      "1597/1597 [==============================] - 1s 884us/step - loss: 0.3509 - accuracy: 0.8768 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 383/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3522 - accuracy: 0.8768 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 384/600\n",
      "1597/1597 [==============================] - 1s 887us/step - loss: 0.3512 - accuracy: 0.8766 - val_loss: 0.3515 - val_accuracy: 0.8775\n",
      "Epoch 385/600\n",
      "1597/1597 [==============================] - 1s 889us/step - loss: 0.3507 - accuracy: 0.8768 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 386/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 1s 885us/step - loss: 0.3506 - accuracy: 0.8766 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 387/600\n",
      "1597/1597 [==============================] - 1s 888us/step - loss: 0.3515 - accuracy: 0.8765 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 388/600\n",
      "1597/1597 [==============================] - 1s 916us/step - loss: 0.3508 - accuracy: 0.8766 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 389/600\n",
      "1597/1597 [==============================] - 1s 910us/step - loss: 0.3511 - accuracy: 0.8768 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 390/600\n",
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3520 - accuracy: 0.8768 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 391/600\n",
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3514 - accuracy: 0.8768 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 392/600\n",
      "1597/1597 [==============================] - 1s 917us/step - loss: 0.3513 - accuracy: 0.8764 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 393/600\n",
      "1597/1597 [==============================] - 2s 979us/step - loss: 0.3515 - accuracy: 0.8768 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 394/600\n",
      "1597/1597 [==============================] - 1s 913us/step - loss: 0.3526 - accuracy: 0.8768 - val_loss: 0.3533 - val_accuracy: 0.8775\n",
      "Epoch 395/600\n",
      "1597/1597 [==============================] - 1s 920us/step - loss: 0.3502 - accuracy: 0.8772 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 396/600\n",
      "1597/1597 [==============================] - 1s 928us/step - loss: 0.3519 - accuracy: 0.8766 - val_loss: 0.3515 - val_accuracy: 0.8775\n",
      "Epoch 397/600\n",
      "1597/1597 [==============================] - 1s 933us/step - loss: 0.3516 - accuracy: 0.8768 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 398/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3508 - accuracy: 0.8768 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 399/600\n",
      "1597/1597 [==============================] - 2s 960us/step - loss: 0.3518 - accuracy: 0.8766 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 400/600\n",
      "1597/1597 [==============================] - 2s 953us/step - loss: 0.3512 - accuracy: 0.8769 - val_loss: 0.3513 - val_accuracy: 0.8775\n",
      "Epoch 401/600\n",
      "1597/1597 [==============================] - 1s 927us/step - loss: 0.3512 - accuracy: 0.8767 - val_loss: 0.3513 - val_accuracy: 0.8775\n",
      "Epoch 402/600\n",
      "1597/1597 [==============================] - 1s 939us/step - loss: 0.3510 - accuracy: 0.8768 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 403/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3519 - accuracy: 0.8766 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 404/600\n",
      "1597/1597 [==============================] - 1s 913us/step - loss: 0.3512 - accuracy: 0.8766 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 405/600\n",
      "1597/1597 [==============================] - 1s 930us/step - loss: 0.3519 - accuracy: 0.8767 - val_loss: 0.3540 - val_accuracy: 0.8775\n",
      "Epoch 406/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3513 - accuracy: 0.8767 - val_loss: 0.3509 - val_accuracy: 0.8775\n",
      "Epoch 407/600\n",
      "1597/1597 [==============================] - 1s 902us/step - loss: 0.3517 - accuracy: 0.8766 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 408/600\n",
      "1597/1597 [==============================] - 1s 897us/step - loss: 0.3510 - accuracy: 0.8769 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 409/600\n",
      "1597/1597 [==============================] - 1s 903us/step - loss: 0.3511 - accuracy: 0.8767 - val_loss: 0.3510 - val_accuracy: 0.8775\n",
      "Epoch 410/600\n",
      "1597/1597 [==============================] - 1s 921us/step - loss: 0.3507 - accuracy: 0.8766 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 411/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3511 - accuracy: 0.8768 - val_loss: 0.3511 - val_accuracy: 0.8775\n",
      "Epoch 412/600\n",
      "1597/1597 [==============================] - 1s 901us/step - loss: 0.3515 - accuracy: 0.8768 - val_loss: 0.3529 - val_accuracy: 0.8775\n",
      "Epoch 413/600\n",
      "1597/1597 [==============================] - 1s 919us/step - loss: 0.3512 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 414/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3514 - accuracy: 0.8770 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 415/600\n",
      "1597/1597 [==============================] - 1s 907us/step - loss: 0.3510 - accuracy: 0.8766 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 416/600\n",
      "1597/1597 [==============================] - 1s 905us/step - loss: 0.3515 - accuracy: 0.8769 - val_loss: 0.3528 - val_accuracy: 0.8775\n",
      "Epoch 417/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3515 - accuracy: 0.8768 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 418/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3505 - accuracy: 0.8770 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 419/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3512 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 420/600\n",
      "1597/1597 [==============================] - 2s 992us/step - loss: 0.3511 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 421/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3512 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 422/600\n",
      "1597/1597 [==============================] - 2s 966us/step - loss: 0.3510 - accuracy: 0.8769 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 423/600\n",
      "1597/1597 [==============================] - 2s 973us/step - loss: 0.3507 - accuracy: 0.8767 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 424/600\n",
      "1597/1597 [==============================] - 2s 955us/step - loss: 0.3506 - accuracy: 0.8771 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 425/600\n",
      "1597/1597 [==============================] - 2s 946us/step - loss: 0.3517 - accuracy: 0.8768 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 426/600\n",
      "1597/1597 [==============================] - 1s 938us/step - loss: 0.3510 - accuracy: 0.8769 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 427/600\n",
      "1597/1597 [==============================] - 2s 940us/step - loss: 0.3504 - accuracy: 0.8769 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 428/600\n",
      "1597/1597 [==============================] - 2s 945us/step - loss: 0.3508 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 429/600\n",
      "1597/1597 [==============================] - 2s 961us/step - loss: 0.3505 - accuracy: 0.8766 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 430/600\n",
      "1597/1597 [==============================] - 2s 957us/step - loss: 0.3506 - accuracy: 0.8766 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 431/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3512 - accuracy: 0.8767 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 432/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3514 - accuracy: 0.8770 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 433/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3515 - accuracy: 0.8766 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 434/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3502 - accuracy: 0.8770 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 435/600\n",
      "1597/1597 [==============================] - 2s 988us/step - loss: 0.3510 - accuracy: 0.8766 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 436/600\n",
      "1597/1597 [==============================] - 2s 978us/step - loss: 0.3501 - accuracy: 0.8770 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 437/600\n",
      "1597/1597 [==============================] - 2s 979us/step - loss: 0.3514 - accuracy: 0.8768 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 438/600\n",
      "1597/1597 [==============================] - 2s 981us/step - loss: 0.3511 - accuracy: 0.8767 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 439/600\n",
      "1597/1597 [==============================] - 2s 999us/step - loss: 0.3511 - accuracy: 0.8765 - val_loss: 0.3534 - val_accuracy: 0.8775\n",
      "Epoch 440/600\n",
      "1597/1597 [==============================] - 2s 989us/step - loss: 0.3511 - accuracy: 0.8769 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 441/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 2s 946us/step - loss: 0.3510 - accuracy: 0.8768 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 442/600\n",
      "1597/1597 [==============================] - 2s 942us/step - loss: 0.3506 - accuracy: 0.8768 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 443/600\n",
      "1597/1597 [==============================] - 2s 945us/step - loss: 0.3516 - accuracy: 0.8767 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 444/600\n",
      "1597/1597 [==============================] - 1s 939us/step - loss: 0.3515 - accuracy: 0.8767 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 445/600\n",
      "1597/1597 [==============================] - 1s 939us/step - loss: 0.3506 - accuracy: 0.8769 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 446/600\n",
      "1597/1597 [==============================] - 2s 962us/step - loss: 0.3515 - accuracy: 0.8764 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 447/600\n",
      "1597/1597 [==============================] - 2s 944us/step - loss: 0.3512 - accuracy: 0.8769 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 448/600\n",
      "1597/1597 [==============================] - 2s 944us/step - loss: 0.3509 - accuracy: 0.8766 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 449/600\n",
      "1597/1597 [==============================] - 1s 938us/step - loss: 0.3516 - accuracy: 0.8767 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 450/600\n",
      "1597/1597 [==============================] - 2s 941us/step - loss: 0.3517 - accuracy: 0.8767 - val_loss: 0.3528 - val_accuracy: 0.8775\n",
      "Epoch 451/600\n",
      "1597/1597 [==============================] - 1s 938us/step - loss: 0.3510 - accuracy: 0.8769 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 452/600\n",
      "1597/1597 [==============================] - 2s 941us/step - loss: 0.3511 - accuracy: 0.8766 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 453/600\n",
      "1597/1597 [==============================] - 2s 940us/step - loss: 0.3514 - accuracy: 0.8768 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 454/600\n",
      "1597/1597 [==============================] - 1s 936us/step - loss: 0.3513 - accuracy: 0.8767 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 455/600\n",
      "1597/1597 [==============================] - 1s 939us/step - loss: 0.3514 - accuracy: 0.8767 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 456/600\n",
      "1597/1597 [==============================] - 1s 938us/step - loss: 0.3507 - accuracy: 0.8769 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 457/600\n",
      "1597/1597 [==============================] - 1s 936us/step - loss: 0.3520 - accuracy: 0.8767 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 458/600\n",
      "1597/1597 [==============================] - 1s 934us/step - loss: 0.3514 - accuracy: 0.8769 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 459/600\n",
      "1597/1597 [==============================] - 2s 941us/step - loss: 0.3509 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 460/600\n",
      "1597/1597 [==============================] - 1s 939us/step - loss: 0.3511 - accuracy: 0.8768 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 461/600\n",
      "1597/1597 [==============================] - 2s 943us/step - loss: 0.3509 - accuracy: 0.8769 - val_loss: 0.3531 - val_accuracy: 0.8775\n",
      "Epoch 462/600\n",
      "1597/1597 [==============================] - 2s 943us/step - loss: 0.3515 - accuracy: 0.8766 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 463/600\n",
      "1597/1597 [==============================] - 2s 946us/step - loss: 0.3512 - accuracy: 0.8768 - val_loss: 0.3538 - val_accuracy: 0.8775\n",
      "Epoch 464/600\n",
      "1597/1597 [==============================] - 2s 954us/step - loss: 0.3514 - accuracy: 0.8770 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 465/600\n",
      "1597/1597 [==============================] - 2s 949us/step - loss: 0.3510 - accuracy: 0.8768 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 466/600\n",
      "1597/1597 [==============================] - 2s 949us/step - loss: 0.3509 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 467/600\n",
      "1597/1597 [==============================] - 2s 974us/step - loss: 0.3511 - accuracy: 0.8768 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 468/600\n",
      "1597/1597 [==============================] - 2s 982us/step - loss: 0.3510 - accuracy: 0.8769 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 469/600\n",
      "1597/1597 [==============================] - 2s 961us/step - loss: 0.3505 - accuracy: 0.8768 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 470/600\n",
      "1597/1597 [==============================] - 2s 953us/step - loss: 0.3510 - accuracy: 0.8771 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 471/600\n",
      "1597/1597 [==============================] - 2s 973us/step - loss: 0.3506 - accuracy: 0.8768 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 472/600\n",
      "1597/1597 [==============================] - 2s 947us/step - loss: 0.3503 - accuracy: 0.8767 - val_loss: 0.3534 - val_accuracy: 0.8775\n",
      "Epoch 473/600\n",
      "1597/1597 [==============================] - 2s 945us/step - loss: 0.3508 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 474/600\n",
      "1597/1597 [==============================] - 2s 939us/step - loss: 0.3502 - accuracy: 0.8766 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 475/600\n",
      "1597/1597 [==============================] - 2s 941us/step - loss: 0.3511 - accuracy: 0.8769 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 476/600\n",
      "1597/1597 [==============================] - 1s 939us/step - loss: 0.3515 - accuracy: 0.8765 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 477/600\n",
      "1597/1597 [==============================] - 2s 948us/step - loss: 0.3513 - accuracy: 0.8768 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 478/600\n",
      "1597/1597 [==============================] - 2s 951us/step - loss: 0.3504 - accuracy: 0.8770 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 479/600\n",
      "1597/1597 [==============================] - 2s 947us/step - loss: 0.3505 - accuracy: 0.8767 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 480/600\n",
      "1597/1597 [==============================] - 2s 951us/step - loss: 0.3521 - accuracy: 0.8762 - val_loss: 0.3531 - val_accuracy: 0.8775\n",
      "Epoch 481/600\n",
      "1597/1597 [==============================] - 2s 945us/step - loss: 0.3508 - accuracy: 0.8769 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 482/600\n",
      "1597/1597 [==============================] - 2s 946us/step - loss: 0.3516 - accuracy: 0.8768 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 483/600\n",
      "1597/1597 [==============================] - 2s 947us/step - loss: 0.3509 - accuracy: 0.8770 - val_loss: 0.3528 - val_accuracy: 0.8775\n",
      "Epoch 484/600\n",
      "1597/1597 [==============================] - 2s 947us/step - loss: 0.3517 - accuracy: 0.8766 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 485/600\n",
      "1597/1597 [==============================] - 2s 944us/step - loss: 0.3514 - accuracy: 0.8770 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 486/600\n",
      "1597/1597 [==============================] - 2s 944us/step - loss: 0.3513 - accuracy: 0.8765 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 487/600\n",
      "1597/1597 [==============================] - 2s 946us/step - loss: 0.3505 - accuracy: 0.8766 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 488/600\n",
      "1597/1597 [==============================] - 2s 944us/step - loss: 0.3505 - accuracy: 0.8769 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 489/600\n",
      "1597/1597 [==============================] - 2s 949us/step - loss: 0.3506 - accuracy: 0.8768 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 490/600\n",
      "1597/1597 [==============================] - 2s 946us/step - loss: 0.3511 - accuracy: 0.8770 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 491/600\n",
      "1597/1597 [==============================] - 2s 943us/step - loss: 0.3516 - accuracy: 0.8767 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 492/600\n",
      "1597/1597 [==============================] - 2s 946us/step - loss: 0.3512 - accuracy: 0.8768 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 493/600\n",
      "1597/1597 [==============================] - 2s 949us/step - loss: 0.3519 - accuracy: 0.8767 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 494/600\n",
      "1597/1597 [==============================] - 2s 948us/step - loss: 0.3513 - accuracy: 0.8769 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 495/600\n",
      "1597/1597 [==============================] - 2s 946us/step - loss: 0.3508 - accuracy: 0.8771 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 496/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 2s 996us/step - loss: 0.3509 - accuracy: 0.8769 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 497/600\n",
      "1597/1597 [==============================] - 2s 987us/step - loss: 0.3506 - accuracy: 0.8765 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 498/600\n",
      "1597/1597 [==============================] - 2s 955us/step - loss: 0.3509 - accuracy: 0.8767 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 499/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3502 - accuracy: 0.8767 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 500/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3506 - accuracy: 0.8768 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 501/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3512 - accuracy: 0.8766 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 502/600\n",
      "1597/1597 [==============================] - 2s 952us/step - loss: 0.3512 - accuracy: 0.8767 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 503/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3513 - accuracy: 0.8766 - val_loss: 0.3517 - val_accuracy: 0.8775\n",
      "Epoch 504/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3505 - accuracy: 0.8767 - val_loss: 0.3514 - val_accuracy: 0.8775\n",
      "Epoch 505/600\n",
      "1597/1597 [==============================] - 2s 958us/step - loss: 0.3511 - accuracy: 0.8767 - val_loss: 0.3532 - val_accuracy: 0.8775\n",
      "Epoch 506/600\n",
      "1597/1597 [==============================] - 2s 986us/step - loss: 0.3506 - accuracy: 0.8768 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 507/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3503 - accuracy: 0.8766 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 508/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3512 - accuracy: 0.8767 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 509/600\n",
      "1597/1597 [==============================] - 2s 971us/step - loss: 0.3504 - accuracy: 0.8767 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 510/600\n",
      "1597/1597 [==============================] - 2s 966us/step - loss: 0.3512 - accuracy: 0.8766 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 511/600\n",
      "1597/1597 [==============================] - 1s 929us/step - loss: 0.3506 - accuracy: 0.8770 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 512/600\n",
      "1597/1597 [==============================] - 2s 943us/step - loss: 0.3509 - accuracy: 0.8768 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 513/600\n",
      "1597/1597 [==============================] - 2s 949us/step - loss: 0.3507 - accuracy: 0.8765 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 514/600\n",
      "1597/1597 [==============================] - 1s 930us/step - loss: 0.3504 - accuracy: 0.8766 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 515/600\n",
      "1597/1597 [==============================] - 1s 921us/step - loss: 0.3515 - accuracy: 0.8768 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 516/600\n",
      "1597/1597 [==============================] - 2s 941us/step - loss: 0.3503 - accuracy: 0.8768 - val_loss: 0.3516 - val_accuracy: 0.8775\n",
      "Epoch 517/600\n",
      "1597/1597 [==============================] - 2s 953us/step - loss: 0.3512 - accuracy: 0.8767 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 518/600\n",
      "1597/1597 [==============================] - 1s 924us/step - loss: 0.3507 - accuracy: 0.8769 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 519/600\n",
      "1597/1597 [==============================] - 1s 923us/step - loss: 0.3512 - accuracy: 0.8769 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 520/600\n",
      "1597/1597 [==============================] - 1s 923us/step - loss: 0.3498 - accuracy: 0.8767 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 521/600\n",
      "1597/1597 [==============================] - 1s 917us/step - loss: 0.3508 - accuracy: 0.8766 - val_loss: 0.3539 - val_accuracy: 0.8775\n",
      "Epoch 522/600\n",
      "1597/1597 [==============================] - 2s 957us/step - loss: 0.3509 - accuracy: 0.8766 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 523/600\n",
      "1597/1597 [==============================] - 2s 962us/step - loss: 0.3508 - accuracy: 0.8766 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 524/600\n",
      "1597/1597 [==============================] - 2s 948us/step - loss: 0.3502 - accuracy: 0.8769 - val_loss: 0.3529 - val_accuracy: 0.8775\n",
      "Epoch 525/600\n",
      "1597/1597 [==============================] - 1s 935us/step - loss: 0.3513 - accuracy: 0.8766 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 526/600\n",
      "1597/1597 [==============================] - 1s 931us/step - loss: 0.3509 - accuracy: 0.8768 - val_loss: 0.3537 - val_accuracy: 0.8775\n",
      "Epoch 527/600\n",
      "1597/1597 [==============================] - 1s 923us/step - loss: 0.3506 - accuracy: 0.8767 - val_loss: 0.3534 - val_accuracy: 0.8775\n",
      "Epoch 528/600\n",
      "1597/1597 [==============================] - 2s 948us/step - loss: 0.3505 - accuracy: 0.8769 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 529/600\n",
      "1597/1597 [==============================] - 2s 999us/step - loss: 0.3512 - accuracy: 0.8766 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 530/600\n",
      "1597/1597 [==============================] - 2s 954us/step - loss: 0.3502 - accuracy: 0.8764 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 531/600\n",
      "1597/1597 [==============================] - 1s 930us/step - loss: 0.3512 - accuracy: 0.8766 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 532/600\n",
      "1597/1597 [==============================] - 1s 933us/step - loss: 0.3499 - accuracy: 0.8770 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 533/600\n",
      "1597/1597 [==============================] - 1s 929us/step - loss: 0.3514 - accuracy: 0.8768 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 534/600\n",
      "1597/1597 [==============================] - 1s 938us/step - loss: 0.3506 - accuracy: 0.8771 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 535/600\n",
      "1597/1597 [==============================] - 1s 928us/step - loss: 0.3510 - accuracy: 0.8766 - val_loss: 0.3543 - val_accuracy: 0.8775\n",
      "Epoch 536/600\n",
      "1597/1597 [==============================] - 1s 926us/step - loss: 0.3518 - accuracy: 0.8768 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 537/600\n",
      "1597/1597 [==============================] - 1s 923us/step - loss: 0.3502 - accuracy: 0.8770 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 538/600\n",
      "1597/1597 [==============================] - 1s 929us/step - loss: 0.3514 - accuracy: 0.8768 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 539/600\n",
      "1597/1597 [==============================] - 1s 928us/step - loss: 0.3497 - accuracy: 0.8768 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 540/600\n",
      "1597/1597 [==============================] - 1s 923us/step - loss: 0.3504 - accuracy: 0.8766 - val_loss: 0.3531 - val_accuracy: 0.8775\n",
      "Epoch 541/600\n",
      "1597/1597 [==============================] - 1s 923us/step - loss: 0.3506 - accuracy: 0.8769 - val_loss: 0.3531 - val_accuracy: 0.8775\n",
      "Epoch 542/600\n",
      "1597/1597 [==============================] - 1s 923us/step - loss: 0.3514 - accuracy: 0.8768 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 543/600\n",
      "1597/1597 [==============================] - 1s 925us/step - loss: 0.3505 - accuracy: 0.8768 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 544/600\n",
      "1597/1597 [==============================] - 1s 925us/step - loss: 0.3504 - accuracy: 0.8766 - val_loss: 0.3533 - val_accuracy: 0.8775\n",
      "Epoch 545/600\n",
      "1597/1597 [==============================] - 1s 929us/step - loss: 0.3506 - accuracy: 0.8769 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 546/600\n",
      "1597/1597 [==============================] - 2s 963us/step - loss: 0.3511 - accuracy: 0.8767 - val_loss: 0.3531 - val_accuracy: 0.8775\n",
      "Epoch 547/600\n",
      "1597/1597 [==============================] - 2s 953us/step - loss: 0.3502 - accuracy: 0.8768 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 548/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3512 - accuracy: 0.8764 - val_loss: 0.3532 - val_accuracy: 0.8775\n",
      "Epoch 549/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3500 - accuracy: 0.8769 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 550/600\n",
      "1597/1597 [==============================] - 1s 933us/step - loss: 0.3505 - accuracy: 0.8767 - val_loss: 0.3532 - val_accuracy: 0.8775\n",
      "Epoch 551/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597/1597 [==============================] - 2s 942us/step - loss: 0.3512 - accuracy: 0.8766 - val_loss: 0.3528 - val_accuracy: 0.8775\n",
      "Epoch 552/600\n",
      "1597/1597 [==============================] - 2s 975us/step - loss: 0.3497 - accuracy: 0.8768 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 553/600\n",
      "1597/1597 [==============================] - 2s 961us/step - loss: 0.3511 - accuracy: 0.8767 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 554/600\n",
      "1597/1597 [==============================] - 1s 936us/step - loss: 0.3503 - accuracy: 0.8766 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 555/600\n",
      "1597/1597 [==============================] - 2s 961us/step - loss: 0.3508 - accuracy: 0.8768 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 556/600\n",
      "1597/1597 [==============================] - 1s 939us/step - loss: 0.3508 - accuracy: 0.8767 - val_loss: 0.3529 - val_accuracy: 0.8775\n",
      "Epoch 557/600\n",
      "1597/1597 [==============================] - 2s 979us/step - loss: 0.3514 - accuracy: 0.8769 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 558/600\n",
      "1597/1597 [==============================] - 1s 928us/step - loss: 0.3505 - accuracy: 0.8767 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 559/600\n",
      "1597/1597 [==============================] - 1s 916us/step - loss: 0.3510 - accuracy: 0.8768 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 560/600\n",
      "1597/1597 [==============================] - 2s 956us/step - loss: 0.3510 - accuracy: 0.8770 - val_loss: 0.3537 - val_accuracy: 0.8775\n",
      "Epoch 561/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3503 - accuracy: 0.8769 - val_loss: 0.3526 - val_accuracy: 0.8774\n",
      "Epoch 562/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3510 - accuracy: 0.8767 - val_loss: 0.3529 - val_accuracy: 0.8775\n",
      "Epoch 563/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3516 - accuracy: 0.8768 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 564/600\n",
      "1597/1597 [==============================] - 2s 981us/step - loss: 0.3515 - accuracy: 0.8768 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 565/600\n",
      "1597/1597 [==============================] - 2s 955us/step - loss: 0.3508 - accuracy: 0.8768 - val_loss: 0.3542 - val_accuracy: 0.8775\n",
      "Epoch 566/600\n",
      "1597/1597 [==============================] - 2s 976us/step - loss: 0.3509 - accuracy: 0.8767 - val_loss: 0.3531 - val_accuracy: 0.8775\n",
      "Epoch 567/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3502 - accuracy: 0.8767 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 568/600\n",
      "1597/1597 [==============================] - 2s 975us/step - loss: 0.3509 - accuracy: 0.8767 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 569/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3505 - accuracy: 0.8766 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 570/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3497 - accuracy: 0.8764 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 571/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3504 - accuracy: 0.8768 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 572/600\n",
      "1597/1597 [==============================] - 2s 1ms/step - loss: 0.3504 - accuracy: 0.8768 - val_loss: 0.3541 - val_accuracy: 0.8774\n",
      "Epoch 573/600\n",
      "1597/1597 [==============================] - 2s 987us/step - loss: 0.3511 - accuracy: 0.8765 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 574/600\n",
      "1597/1597 [==============================] - 1s 928us/step - loss: 0.3496 - accuracy: 0.8770 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 575/600\n",
      "1597/1597 [==============================] - 1s 926us/step - loss: 0.3503 - accuracy: 0.8768 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 576/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3507 - accuracy: 0.8767 - val_loss: 0.3519 - val_accuracy: 0.8775\n",
      "Epoch 577/600\n",
      "1597/1597 [==============================] - 1s 911us/step - loss: 0.3505 - accuracy: 0.8769 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 578/600\n",
      "1597/1597 [==============================] - 1s 924us/step - loss: 0.3515 - accuracy: 0.8768 - val_loss: 0.3531 - val_accuracy: 0.8775\n",
      "Epoch 579/600\n",
      "1597/1597 [==============================] - 1s 913us/step - loss: 0.3499 - accuracy: 0.8768 - val_loss: 0.3536 - val_accuracy: 0.8775\n",
      "Epoch 580/600\n",
      "1597/1597 [==============================] - 1s 919us/step - loss: 0.3515 - accuracy: 0.8769 - val_loss: 0.3523 - val_accuracy: 0.8775\n",
      "Epoch 581/600\n",
      "1597/1597 [==============================] - 1s 910us/step - loss: 0.3510 - accuracy: 0.8770 - val_loss: 0.3527 - val_accuracy: 0.8775\n",
      "Epoch 582/600\n",
      "1597/1597 [==============================] - 1s 912us/step - loss: 0.3517 - accuracy: 0.8765 - val_loss: 0.3535 - val_accuracy: 0.8775\n",
      "Epoch 583/600\n",
      "1597/1597 [==============================] - 1s 917us/step - loss: 0.3516 - accuracy: 0.8765 - val_loss: 0.3525 - val_accuracy: 0.8775\n",
      "Epoch 584/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3510 - accuracy: 0.8769 - val_loss: 0.3522 - val_accuracy: 0.8775\n",
      "Epoch 585/600\n",
      "1597/1597 [==============================] - 1s 911us/step - loss: 0.3506 - accuracy: 0.8767 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 586/600\n",
      "1597/1597 [==============================] - 1s 921us/step - loss: 0.3507 - accuracy: 0.8767 - val_loss: 0.3529 - val_accuracy: 0.8775\n",
      "Epoch 587/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3505 - accuracy: 0.8768 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 588/600\n",
      "1597/1597 [==============================] - 1s 921us/step - loss: 0.3507 - accuracy: 0.8767 - val_loss: 0.3535 - val_accuracy: 0.8775\n",
      "Epoch 589/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3515 - accuracy: 0.8765 - val_loss: 0.3529 - val_accuracy: 0.8775\n",
      "Epoch 590/600\n",
      "1597/1597 [==============================] - 1s 917us/step - loss: 0.3511 - accuracy: 0.8765 - val_loss: 0.3536 - val_accuracy: 0.8775\n",
      "Epoch 591/600\n",
      "1597/1597 [==============================] - 1s 913us/step - loss: 0.3506 - accuracy: 0.8764 - val_loss: 0.3534 - val_accuracy: 0.8775\n",
      "Epoch 592/600\n",
      "1597/1597 [==============================] - 1s 913us/step - loss: 0.3501 - accuracy: 0.8766 - val_loss: 0.3521 - val_accuracy: 0.8775\n",
      "Epoch 593/600\n",
      "1597/1597 [==============================] - 1s 912us/step - loss: 0.3508 - accuracy: 0.8769 - val_loss: 0.3528 - val_accuracy: 0.8775\n",
      "Epoch 594/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3507 - accuracy: 0.8768 - val_loss: 0.3520 - val_accuracy: 0.8775\n",
      "Epoch 595/600\n",
      "1597/1597 [==============================] - 1s 911us/step - loss: 0.3497 - accuracy: 0.8769 - val_loss: 0.3524 - val_accuracy: 0.8775\n",
      "Epoch 596/600\n",
      "1597/1597 [==============================] - 1s 912us/step - loss: 0.3512 - accuracy: 0.8769 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 597/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3505 - accuracy: 0.8768 - val_loss: 0.3530 - val_accuracy: 0.8775\n",
      "Epoch 598/600\n",
      "1597/1597 [==============================] - 1s 915us/step - loss: 0.3512 - accuracy: 0.8766 - val_loss: 0.3534 - val_accuracy: 0.8775\n",
      "Epoch 599/600\n",
      "1597/1597 [==============================] - 1s 914us/step - loss: 0.3506 - accuracy: 0.8765 - val_loss: 0.3526 - val_accuracy: 0.8775\n",
      "Epoch 600/600\n",
      "1597/1597 [==============================] - 2s 951us/step - loss: 0.3513 - accuracy: 0.8769 - val_loss: 0.3534 - val_accuracy: 0.8775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27511a71b20>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27505e37460>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZRcdZ3//+e71l7TS/Y9YQyGrCwdUBzDku8g+AtEGdAgw0iOwkEFHTgyLIryHdBxcBtn5CeT8QfICN/AARkZZOArEgl6cEyCgSRkIYQlnbX3TnV3bfd+fn/cSqfS6U4q0El3la/HOX267r2fe+/7c6vq1Z+6XXXLnHOIiEjxCw11ASIiMjgU6CIiJUKBLiJSIhToIiIlQoEuIlIiFOgiIiWioEA3swvNbIuZbTOzW/tZXmdmT5rZa2b2RzObM/iliojIkRw10M0sDNwLXATMAq4ws1l9mt0OrHPOzQP+FvjRYBcqIiJHFimgzZnANufcdgAzWwEsAV7PazML+EcA59xmM5tmZmOdc3sH2uioUaPctGnT3nPhIiJ/jtauXdvsnBvd37JCAn0isCNvuhE4q0+bV4FLgd+Z2ZnAVGASMGCgT5s2jTVr1hSwexEROcDM3hloWSHn0K2feX2vF/AdoM7M1gE3AH8Csv0Ucq2ZrTGzNU1NTQXsWkREClXICL0RmJw3PQnYld/AOdcJLAMwMwPeyv3Qp91yYDlAQ0ODLiIjIjKIChmhrwZmmNl0M4sBS4Gn8huYWW1uGcDngVW5kBcRkRPkqCN051zWzK4HngPCwP3OuY1mdl1u+X3AKcBDZuYR/LP0c8exZhER6Uchp1xwzj0DPNNn3n15t18GZgxuaSIiciz0SVERkRKhQBcRKREFnXIZTlJvvsn+Z56CRP5b3C335krjkHdZmh1cfsh0f+vlT/c3z8DCkO0BC4GXBecH80Ih8P2gne8Fq4XC4GeD9cIR8DLBfOdDKAqRGGRy2wr1vRtc7o2heb9xQbtQBLx08GMhOPCNU9kkRMogUg4um6vDgj5b7rhYKPg5MN9LBduJlOW243p3f+g7UweaT1CPGc73gmMSCh88zl42dwwObMaDaEXefWHB8YCD/eh7HA6ZPNY27vAmkfjBvnppCMeD+8JCufvIBct76/LzNmDgZ4Ll4djB45lNBdvIJoFQcBuDTHfw+DCC++WwugZ4o5eXCmoJhQ/e574fHD/ncsfO5e7//A7mHi/ZHohVBbN8L1er5e0610cvnWuTCe4X54LHZLQs1zcL+nag1mh5MG2h3IYsqDH/PjQL7vP8YxOOBXVkk8E2QtGDfTUL6vA9CEeDOvxMsA0/G6wfLQ+2ceA+yH9epxN5z4vcetHyoK6DOwlqTHflHgNlB5+bB4TCueOZ64uFcvcnh94XFj7YNhSGZGdQm/Py6gvlPedy+8gmg36HI5BNU97QQNXHP9X//f8+FF+gb3yVpnuXD3UZIlK0hv4d0yP3blagA1RP6mHmp/bAJ34CVWPpHW1A3u2833DoqOSwZa6fZQO0z6agrCZYHInnRuHewZGdn4VY5cHRXv7vaFnw19/5wfbSiWBbzods+uA+80fQh4ywgVQi2Ee8GmIV0N0W3A4ZlNVCTxskO4IRSDg3CnJ+UKPzcr9zIz3fD/oQq4BMMm/0zuGji76vXPJf6SSagu1EyoKRSqYn2L6Fgz7Hqg+2NYOe9uD3gWMRih7+quiQV1J95xXwCswGWs/B/t1BnaEoxKsg3Q3p/cGxiZbnXi3lXlX19jc34sr0BLPKaoNRtJ8NRmhVY4LR34H1U4lglFw1NmjjfEi293NMrZ86CY5lWU3weMsmc6Nkd/DVTbIDymuDmg+5r3K/nYPU/qBtrBLLdOdeTfbZt4WDx0msMne/hILb2WRuhJwbNTsXvOroacs9vnMj1J623Ki6PK+tH7zq8TPB46qiPjg24RiUjYDu1oOvDDDo2hf0NVaZO265UXykLPiJVwX7SXdz6Kun3O3yuuDxlk0F24iU9dlH3nO6clTu1W0mqNXLBvez7wfzU/tzz+/cc7msNjhOB0b02WSw7oFteJngfjhwfLCDz63e51nuOVdeF6yf7gr2PeXDHA9FF+h2+pUw5SwY9YGhLkVEZFgpzn+KKsxFRA5TnIEuIiKHUaCLiJQIBbqISIlQoIuIlAgFuohIiVCgi4iUCAW6iEiJUKCLiJQIBbqISIlQoIuIlAgFuohIiVCgi4iUCAW6iEiJUKCLiJQIBbqISIlQoIuIlAgFuohIiVCgi4iUCAW6iEiJUKCLiJQIBbqISIlQoIuIlIiCAt3MLjSzLWa2zcxu7Wd5jZn9l5m9amYbzWzZ4JcqIiJHctRAN7MwcC9wETALuMLMZvVp9iXgdefcfOBc4PtmFhvkWkVE5AgKGaGfCWxzzm13zqWBFcCSPm0cUG1mBlQBrUB2UCsVEZEjKiTQJwI78qYbc/Py/Rg4BdgFrAe+4pzz+27IzK41szVmtqapqek9liwiIv0pJNCtn3muz/THgHXABOBU4MdmNuKwlZxb7pxrcM41jB49+piLFRGRgRUS6I3A5LzpSQQj8XzLgF+4wDbgLWDm4JQoIiKFKCTQVwMzzGx67h+dS4Gn+rR5F1gEYGZjgQ8C2wezUBERObLI0Ro457Jmdj3wHBAG7nfObTSz63LL7wPuAh40s/UEp2hucc41H8e6RUSkj6MGOoBz7hngmT7z7su7vQu4YHBLExGRY6FPioqIlAgFuohIiVCgi4iUCAW6iEiJUKCLiJQIBbqISIlQoIuIlAgFuohIiVCgi4iUCAW6iEiJUKCLiJQIBbqISIlQoIuIlAgFuohIiVCgi4iUCAW6iEiJUKCLiJQIBbqISIlQoIuIlAgFuohIiVCgi4iUCAW6iEiJUKCLiJQIBbqISIlQoIuIlAgFuohIiVCgi4iUCAW6iEiJKCjQzexCM9tiZtvM7NZ+lt9sZutyPxvMzDOz+sEvV0REBnLUQDezMHAvcBEwC7jCzGblt3HOfdc5d6pz7lTgNuBF51zr8ShYRET6V8gI/Uxgm3Nuu3MuDawAlhyh/RXA/xmM4kREpHCFBPpEYEfedGNu3mHMrAK4EHji/ZcmIiLHIlJAG+tnnhug7cXA7wc63WJm1wLXAkyZMqWgAkXkxMhkMjQ2NpJMJoe6FAHKysqYNGkS0Wi04HUKCfRGYHLe9CRg1wBtl3KE0y3OueXAcoCGhoaB/iiIyBBobGykurqaadOmYdbfOE5OFOccLS0tNDY2Mn369ILXK+SUy2pghplNN7MYQWg/1beRmdUA5wC/LHjvIjJsJJNJRo4cqTAfBsyMkSNHHvOrpaOO0J1zWTO7HngOCAP3O+c2mtl1ueX35Zp+Evi/zrmuYytdRIYLhfnw8V7ui0JOueCcewZ4ps+8+/pMPwg8eMwViIjkVFVVkUgkhrqMoqVPioqIlAgFuogMO845br75ZubMmcPcuXN59NFHAdi9ezcLFy7k1FNPZc6cObz00kt4nsfVV1/d2/aHP/zhEFc/dAo65SIif17+939t5PVdnYO6zVkTRvDNi2cX1PYXv/gF69at49VXX6W5uZkFCxawcOFCHnnkET72sY/xta99Dc/z6O7uZt26dezcuZMNGzYA0N7ePqh1FxON0EVk2Pnd737HFVdcQTgcZuzYsZxzzjmsXr2aBQsW8MADD3DnnXeyfv16qqurOemkk9i+fTs33HADzz77LCNGjBjq8oeMRugicphCR9LHi3P9f0xl4cKFrFq1il/96ldcddVV3Hzzzfzt3/4tr776Ks899xz33nsvjz32GPfff/8Jrnh40AhdRIadhQsX8uijj+J5Hk1NTaxatYozzzyTd955hzFjxnDNNdfwuc99jldeeYXm5mZ83+ev//qvueuuu3jllVeGuvwhoxG6iAw7n/zkJ3n55ZeZP38+ZsY999zDuHHj+NnPfsZ3v/tdotEoVVVVPPTQQ+zcuZNly5bh+z4A//iP/zjE1Q8dG+ilzfHW0NDg1qxZMyT7FpHDbdq0iVNOOWWoy5A8/d0nZrbWOdfQX3udchERKREKdBGREqFAFxEpEQp0EZESoUAXESkRCnQRkRKhQBcRKREKdBH5s5PNZoe6hONCgS4iw8onPvEJzjjjDGbPns3y5csBePbZZzn99NOZP38+ixYtAiCRSLBs2TLmzp3LvHnzeOKJJ4DgSzIOePzxx7n66qsBuPrqq7nppps477zzuOWWW/jjH//I2WefzWmnncbZZ5/Nli1bAPA8j69+9au92/3Xf/1XfvOb3/DJT36yd7u//vWvufTSS0/E4Tgm+ui/iBzuv2+FPesHd5vj5sJF3zlqs/vvv5/6+np6enpYsGABS5Ys4ZprrmHVqlVMnz6d1tZWAO666y5qampYvz6os62t7ajb3rp1K88//zzhcJjOzk5WrVpFJBLh+eef5/bbb+eJJ55g+fLlvPXWW/zpT38iEonQ2tpKXV0dX/rSl2hqamL06NE88MADLFu27P0dj+NAgS4iw8q//Mu/8OSTTwKwY8cOli9fzsKFC5k+fToA9fX1ADz//POsWLGid726urqjbvvyyy8nHA4D0NHRwWc/+1neeOMNzIxMJtO73euuu45IJHLI/q666ip+/vOfs2zZMl5++WUeeuihQerx4FGgi8jhChhJHw+//e1vef7553n55ZepqKjg3HPPZf78+b2nQ/I55/r9IuX8eclk8pBllZWVvbfvuOMOzjvvPJ588knefvttzj333CNud9myZVx88cWUlZVx+eWX9wb+cKJz6CIybHR0dFBXV0dFRQWbN2/mD3/4A6lUihdffJG33noLoPeUywUXXMCPf/zj3nUPnHIZO3YsmzZtwvf93pH+QPuaOHEiAA8++GDv/AsuuID77ruv9x+nB/Y3YcIEJkyYwN133917Xn64UaCLyLBx4YUXks1mmTdvHnfccQcf+tCHGD16NMuXL+fSSy9l/vz5fPrTnwbg61//Om1tbcyZM4f58+ezcuVKAL7zne+wePFizj//fMaPHz/gvv7+7/+e2267jY985CN4ntc7//Of/zxTpkxh3rx5zJ8/n0ceeaR32ZVXXsnkyZOZNWvWcToC748unysigC6fW4jrr7+e0047jc997nMnZH/Hevnc4XcSSERkGDrjjDOorKzk+9///lCXMiAFuohIAdauXTvUJRyVzqGLiJQIBbqISIlQoIuIlAgFuohIiSgo0M3sQjPbYmbbzOzWAdqca2brzGyjmb04uGWKiMjRHDXQzSwM3AtcBMwCrjCzWX3a1AL/L3CJc242cPlxqFVEpFf+VRX7evvtt5kzZ84JrGZ4KGSEfiawzTm33TmXBlYAS/q0+QzwC+fcuwDOuX2DW6aIiBxNIe9DnwjsyJtuBM7q0+ZkIGpmvwWqgR855w67FJmZXQtcCzBlypT3Uq+InAD/9Md/YnPr5kHd5sz6mdxy5i0DLr/llluYOnUqX/ziFwG48847MTNWrVpFW1sbmUyGu+++myVL+o4njyyZTPKFL3yBNWvWEIlE+MEPfsB5553Hxo0bWbZsGel0Gt/3eeKJJ5gwYQKf+tSnaGxsxPM87rjjjt5LDRSDQgL98MuOQd/rBUSAM4BFQDnwspn9wTm39ZCVnFsOLIfgo//HXq6IlKqlS5fyd3/3d72B/thjj/Hss89y4403MmLECJqbm/nQhz7EJZdc0u/VEAdy7733ArB+/Xo2b97MBRdcwNatW7nvvvv4yle+wpVXXkk6ncbzPJ555hkmTJjAr371KyC4gFcxKSTQG4HJedOTgF39tGl2znUBXWa2CpgPbEVEis6RRtLHy2mnnca+ffvYtWsXTU1N1NXVMX78eG688UZWrVpFKBRi586d7N27l3HjxhW83d/97nfccMMNAMycOZOpU6eydetWPvzhD/Otb32LxsZGLr30UmbMmMHcuXP56le/yi233MLixYv56Ec/ery6e1wUcg59NTDDzKabWQxYCjzVp80vgY+aWcTMKghOyWwa3FJFpNRddtllPP744zz66KMsXbqUhx9+mKamJtauXcu6desYO3bsYdc4P5qBLkD4mc98hqeeeory8nI+9rGP8cILL3DyySezdu1a5s6dy2233cY//MM/DEa3TpijjtCdc1kzux54DggD9zvnNprZdbnl9znnNpnZs8BrgA/81Dm34XgWLiKlZ+nSpVxzzTU0Nzfz4osv8thjjzFmzBii0SgrV67knXfeOeZtLly4kIcffpjzzz+frVu38u677/LBD36Q7du3c9JJJ/HlL3+Z7du389prrzFz5kzq6+v5m7/5G6qqqg65TnoxKOjiXM65Z4Bn+sy7r8/0d4HvDl5pIvLnZvbs2ezfv5+JEycyfvx4rrzySi6++GIaGho49dRTmTlz5jFv84tf/CLXXXcdc+fOJRKJ8OCDDxKPx3n00Uf5+c9/TjQaZdy4cXzjG99g9erV3HzzzYRCIaLRKD/5yU+OQy+PH10PXUQAXQ99ODrW66Hro/8iIiVC10MXkaK1fv16rrrqqkPmxeNx/ud//meIKhpaCnQRKVpz585l3bp1Q13GsKFTLiIiJUKBLiJSIhToIiIlQoEuIlIiFOgiUpSOdD30P1cKdBGR9yGbzQ51Cb30tkUROcyeb3+b1KbBvR56/JSZjLv99gGXD+b10BOJBEuWLOl3vYceeojvfe97mBnz5s3jP/7jP9i7dy/XXXcd27dvB+AnP/kJEyZMYPHixWzYEFyW6nvf+x6JRII777yTc889l7PPPpvf//73XHLJJZx88sncfffdpNNpRo4cycMPP8zYsWNJJBLccMMNrFmzBjPjm9/8Ju3t7WzYsIEf/vCHAPz7v/87mzZt4gc/+MH7Or6gQBeRYWIwr4deVlbGk08+edh6r7/+Ot/61rf4/e9/z6hRo2htbQXgy1/+Mueccw5PPvkknueRSCRoa2s74j7a29t58cXg65Pb2tr4wx/+gJnx05/+lHvuuYfvf//73HXXXdTU1LB+/fredrFYjHnz5nHPPfcQjUZ54IEH+Ld/+7f3e/gABbqI9ONII+njZTCvh+6c4/bbbz9svRdeeIHLLruMUaNGAVBfXw/ACy+8wEMPBV+yFg6HqampOWqg53+TUWNjI5/+9KfZvXs36XSa6dOnA/D888+zYsWK3nZ1dXUAnH/++Tz99NOccsopZDIZ5s6de4xHq38KdBEZNg5cD33Pnj2HXQ89Go0ybdq0gq6HPtB6zrmCv+0oEong+37vdN/9VlZW9t6+4YYbuOmmm7jkkkv47W9/y5133gkw4P4+//nP8+1vf5uZM2eybNmyguophP4pKiLDxtKlS1mxYgWPP/44l112GR0dHe/peugDrbdo0SIee+wxWlpaAHpPuSxatKj3Urme59HZ2cnYsWPZt28fLS0tpFIpnn766SPub+LEiQD87Gc/651/wQUX8OMf/7h3+sCo/6yzzmLHjh088sgjXHHFFYUenqNSoIvIsNHf9dDXrFlDQ0MDDz/8cMHXQx9ovdmzZ/O1r32Nc845h/nz53PTTTcB8KMf/YiVK1cyd+5czjjjDDZu3Eg0GuUb3/gGZ511FosXLz7ivu+8804uv/xyPvrRj/aezgH4+te/TltbG3PmzGH+/PmsXLmyd9mnPvUpPvKRj/SehhkMuh66iAC6HvqJtnjxYm688UYWLVo0YBtdD11EZBhrb2/n5JNPpry8/Ihh/l7on6IiUrSK8XrotbW1bN269bhsW4EuIr2O5V0gw0EpXw/9vZwO1ykXEQGCD+O0tLS8pyCRweWco6WlhbKysmNaTyN0EQFg0qRJNDY20tTUNNSlCMEf2EmTJh3TOgp0EQEgGo32fsJRipNOuYiIlAgFuohIiVCgi4iUCAW6iEiJUKCLiJSIggLdzC40sy1mts3Mbu1n+blm1mFm63I/3xj8UkVE5EiO+rZFMwsD9wJ/BTQCq83sKefc632avuScW3wcahQRkQIUMkI/E9jmnNvunEsDK4Cjf6mfiIicUIUE+kRgR950Y25eXx82s1fN7L/NbPagVCciIgUr5JOi/V2pp+/FHl4BpjrnEmb2ceA/gRmHbcjsWuBagClTphxjqSIiciSFjNAbgcl505OAXfkNnHOdzrlE7vYzQNTMRtGHc265c67BOdcwevTo91G2iIj0VUigrwZmmNl0M4sBS4Gn8huY2TjLXXPTzM7MbbdlsIsVEZGBHfWUi3Mua2bXA88BYeB+59xGM7sut/w+4DLgC2aWBXqApU7X4BQROaH0naIiIkVE3ykqIvJnQIEuIlIiFOgiIiVCgS4iUiIU6CIiJUKBLiJSIhToIiIlQoEuIlIiFOgiIiVCgS4iUiIU6CIiJUKBLiJSIhToIiIlQoEuIlIiFOgiIiVCgS4iUiIU6CIiJUKBLiJSIhToIiIlQoEuIlIiFOgiIiVCgS4iUiIU6CIiJUKBLiJSIhToIiIlQoEuIlIiFOgiIiVCgS4iUiIKCnQzu9DMtpjZNjO79QjtFpiZZ2aXDV6JIiJSiKMGupmFgXuBi4BZwBVmNmuAdv8EPDfYRYqIyNEVMkI/E9jmnNvunEsDK4Al/bS7AXgC2DeI9R1my579/ODXW2ntSh/P3YiIFJ1CAn0isCNvujE3r5eZTQQ+Cdw3eKX1b3tTgn/5zRvs7Uwe712JiBSVQgLd+pnn+kz/M3CLc8474obMrjWzNWa2pqmpqdAaD1ERjwDQnc6+p/VFREpVpIA2jcDkvOlJwK4+bRqAFWYGMAr4uJllnXP/md/IObccWA7Q0NDQ949CQSpiYQC600f82yEi8menkEBfDcwws+nATmAp8Jn8Bs656Qdum9mDwNN9w3ywHAj0rpQCXUQk31ED3TmXNbPrCd69Egbud85tNLPrcsuP+3nzfJUxnXIREelPISN0nHPPAM/0mddvkDvnrn7/ZQ2sIp4boeuUi4jIIYruk6K9I/SURugiIvmKLtDLo/qnqIhIf4ou0EMhozwa1jl0EZE+ii7QASrjYZ1DFxHpoygDvSIW0Tl0EZE+ijLQR1bF2N2hj/6LiOQrykCfP6mW1xo7yHr+UJciIjJsFGWgnzG1jp6Mx282H9cLO4qIFJWiDPQLZo9l5rhqvv6fG2hJpIa6HBGRYaHoAn1f9z4e3fIw3/zEVDp6Miy8ZyX3rtzG5j2dvPxmCwn9s1RE/kyZc+/poofvW0NDg1uzZs0xr/dfb/4Xt//udsIWZl7t+by0+jRC0Ta87qlAhFjYp7IsQtiijKyMcdqUWsbWwl+MibGnNQoGteUxWrvT7OlIUlsepWFaPU2JJBXlSWaOGUttWRmt3Wkq42HSWZ9wyBhZGScWCf7+Oedo785QVxk7pLas5xMJF93fSBEpIma21jnX0O+yYgt0gK1tW/nCr7/Avp6D59CNEGGLkHUZwBHyq4hRS5K9EMr0tvNSY/CTE3HZSiJVmyGUJts5n1BZI+GKt/F6puL3TCYUawbz8ZLjcemRxKreJUw5MX8MhLJ0hTZRERpFNBTD9yHlpenqnMyMUaNo7m6lvHovUytn0ZrwSfldVMVD+C6Ml6pjwog63m1vJ0Kc6pq9tCVCuPhb1EWmMm3EyYyuivFmcxtT60ZSUxbntX2bafPfYErFHHoyaZKRTWT9DOWhelJ+gvVNW5gzcj6Lxi2l099BbfkI9nQkqCmPcFL9BDa3vs72rjVMrhmPeSMwrxrPD1NRlqU7u5+JZTMZXz2Kd9r3EXE1jKjdRzIVJh6O0pjYxbTasYQswjsdbzF1xAc4e/Is1u3opIedNEyYRcis9yqYL7+zDT/cwdkTT2dnYg8Tq8eR9cDPPc46kxne3NfFB8ZUURWPEI04whamqaeJWChGbVktAO927mRErLJ3Ol/Gy9CV6SIeqqY8t18I/tC2pdqoi9eRu5QzAIl0grZkG5NHTO5tt2bvGkbERnBy3cm9bdNemkgoQsgO/uHO306hMl6GaDgKQMpL0ZnqZFT5qOBx+h6211cym6QsUjbgsp5sD3Vldb3znHOs3LGShnENjIiNAMDzPcKh8CF9dM6R9bO9tffVnmwnFAr1bmMgPdkeYqEYjYlG9nXvY8G4Bb3LdiZ2MqZ8DA5HNBTFcx6GYWa9xx2CYxgOhQlZiIwfPH+joWhvHX0fFykvRTwcxznHi40v0jC2gUQmwRttb7Bg3AJi4RiGsWLLCs4afxbTRkxjV2IXYyrGsLtrN1XRKtJeGjNjbMVYzIysn8U5xyv7XuG0MafxUuNLeM7jr6b+FUkvyS+3/ZKLpl9ETbyGdzvfJeNn6Mn2MKNuBtFQlG3t29jTtYfJ1ZOZXjMd5xzb2rfRme5kYtVExlWOO+JxHEjJBTpAR6qDV/a+wpsdbzKybCTvdL5DygvOp3dnu9md2E1Xpousy/JWx9t4vs/4ykmEMFpTrfRk95P2g6+xM0KAoyo8hqTfScb1UBWpJ2ZVtGZ2cPj3eQQiVOO7LD5JsKE5jgB+tpJQpOuE7c/5McBhoQx+tiI4fqEkzo9j4W4s71hYdjSenwXzcdkqnB8HF8Yi+wlFO7BQEvOrcKFEcAz9OOZX4yLNOC9O3J+CH0qAHyMb2UHYG48X2Rn0O1MDqanE4/sJU07KdeBiOwn5NZhfTthV45HEj+zGWZYK74NEQ5XEIhmavPVBfS5KODmbkZUVNPl/JEwFMW8ysUiY/e5NYv4EyiIxwn4902omM6V6Ku90v8rW9g146ZEQayTpdVFtJ1EVGsd+fy/72cT0igY8P8Tu1EZSficRqwDLUsVf4FuCqkgdiWwHGZegwn2AytAoLJyiNbWbcCSDTw9ZuqiOjGFkeR2pnmrCER8XaueNxGqi1OI7j6lVM9mfbqPLa6MyNI6m7EacH6E+MoO0a+cD1aezt6uFPd4fAJhcNpcdyfWEiVIerqHba6c+OpWqWCXvdm8EZ0yumEMknOadxBvErJrx5R8gYlHe7FqNw1EfnUo6myFkRiwcpzXTSDxURtQq8bw4nW4bhuEI3oVWHRlJRXgEsXCMHd1beh8b9dGJdGSa8cni8KmNTGFG7QyakrtoTLyJEREOvM0AAAmoSURBVGFErJZur52k101lpJ6ayHh2JjdQFakj5SWJhWOkvR4ybuCvpAxqOfT5OTI2mZb0jn7bl4WrMKDHS/S7vDY2mkjIaE4GA8pRZeNoTu7pXR4PVZHyD103YlF85+MTfCBy0cRP8M//664Baz6Skgz098s5h+98HA7DSPtpysJlZF22dwQQDUXZndhNa6qVaCjK2Iqx7OveR9bPMq1mGuWRcgC6M910pDpo6gm+hSkailIdq2Zj80YcjjEVY6iIVtDS00JrspWWnhbGV46nJ5tiXOVYHD6RUATDWLP7deKhCuorY7QnE2SzYabVjWNq5UzWN22hPJ4i2zWD7Z2vk3VJassruWLuIv77zZWsb3mN2vAU2tLNhAxqY/VsbttAlhQnlf0lEX8CXe4dmr31VEaqqbAJdGZ3YoTJkqEsVE1HspN9+9PMGDkBC2WYVHUSb7S+TTwSxktX8fb+7aTYR21FjKTXyc7OdspDI6grqyfhNRP1R1NTVs6OxHZGx6ewK/U6VdEquvw9xMMVtKWaydBGebiOKvcBwv4oMtZKV3cZ0XhnEPSE8EIdOK+SrOfjOUc8EsZ55WRIkHX78SMtQaC7MGXhKtKhHYQsinNGyK/CC3UQ9usgW4eFu8iEmghnx+EsiU+WGm8BVbFyOtlKgu04smQTs4iHI4TLd5J1PbhQDyEXw3kV+KH9WPjQzz44P0o2cQrRWDfE3wbLQrYGIh15bWJYKI2frgv65lfjZSsh3Eko2hm08WJYOI3zYkT8MWRJYNH23LI4EALLYKHg/0OZ/acQjrVAKA3m4afG4rJVhOJ7CZftBsBP1+K8KkJlu3FeWb9/8LOJGQBYuDv3anQioUgHoWgbzi8HfDAPCyXBRbBYCy5Ti58eg3MhzLygLhcPAjOUDKLTjwOG8yoglMYsG2wnnCBcthcvOQFcqLeNn67H+XEi5Y1YfA8uO4JQfA8uWxW8mvYq8LNVhON7CVe8jYWTZBMn42dHECl/G69nCqF48NzzeiYTLt+B8+L4qfH4qTGEynZjoR6cXx70JZTGIvvxeyZj0Q6cV47LVoOL4lyYUHxvMOiwDI4QhoefrQ3640cJV24LBiiZmt7j4/xycOGDx8uyhCL7SbefRaRiOxZtxUIZvO6T8NP1XDFrCf9wSb+ZfFQKdClZHT0Zasqjvac5nHM4HJ7zel+iA4edWuh76iOV9di2L8Gs8SP6PS2SSGXZ1dHBm+1vMiJWTyjcw+SqkxhVVUY897+VrMsSJkJ7d5oMPZj57GiGt5q7mVxXzqjqCNNHVgPG7s4kXqiFkIuzs9VRV+UxoaaWqlg5Wc9n097d/MWoevZ0eDS2dbNgei2NHU3896Y3WDJrAXWVMTzP0djWgxlUxSNMqivHAS+90cScCTU4wPOzjCgvozxqdCT309jeDS7KyWPq6Ul7mMHGXZ1MqC2nrTtNNBSiK52lvTtNZTzC7Ak1PL52ByEzLjl1Asm0T0tXilFVcTKeTzQcYnR1nJauNCMrY7zb2s34mjL2dqYYUR6hPBpmb2cK5xx7O1O0dKVIZXwaptWxb3+KcMgYUx2nKh4hHg3z+23NVMTCNEytJxI2tuzZT1MiRfP+FA3T6vF8x77OJHs6k1TEIpTHwhjBxfoynk9nMkNP2uMvRlfRk/GorYiytzPJW83dVMbCwf/L9id56Y1mZk+oYXxNGZ3JDIlUlpZEmmg4xM72buZPquWU8SPoTntkfZ+KWITJdeW88m47HT0Z3mpOMKoqzvqdHTRMrQ9OIYVDXDxvAi1dKd7YF4zQp4+s5OXtLRiwZe9+/vIDoxg7oozZE/p/nBVCgS4iUiKOFOh6S4aISIlQoIuIlAgFuohIiVCgi4iUCAW6iEiJUKCLiJQIBbqISIlQoIuIlIgh+2CRmTUB77zH1UcBzYNYzlBSX4Yn9WX4KZV+wPvry1Tn3Oj+FgxZoL8fZrZmoE9KFRv1ZXhSX4afUukHHL++6JSLiEiJUKCLiJSIYg305UNdwCBSX4Yn9WX4KZV+wHHqS1GeQxcRkcMV6whdRET6KLpAN7MLzWyLmW0zs1uHup6jMbP7zWyfmW3Im1dvZr82szdyv+vylt2W69sWM/vY0FR9ODObbGYrzWyTmW00s6/k5hdjX8rM7I9m9mquL/87N7/o+nKAmYXN7E9m9nRuuij7YmZvm9l6M1tnZmty84quL2ZWa2aPm9nm3HPmwyekH865ovkBwsCbwElADHgVmDXUdR2l5oXA6cCGvHn3ALfmbt8K/FPu9qxcn+LA9Fxfw0Pdh1xt44HTc7erga25eouxLwZU5W5Hgf8BPlSMfcnr003AI8DTxfoYy9X3NjCqz7yi6wvwM+DzudsxoPZE9KPYRuhnAtucc9udc2lgBbBkiGs6IufcKqC1z+wlBHc4ud+fyJu/wjmXcs69BWwj6POQc87tds69kru9H9gETKQ4++Kccwe+xTea+3EUYV8AzGwS8P8AP82bXZR9GUBR9cXMRhAM5P4/AOdc2jnXzgnoR7EF+kQg/6u6G3Pzis1Y59xuCIISGJObXxT9M7NpwGkEI9ui7EvuFMU6YB/wa+dc0fYF+Gfg7wE/b16x9sUB/9fM1prZtbl5xdaXk4Am4IHcabCfmlklJ6AfxRbo/X2raim9TWfY98/MqoAngL9zznUeqWk/84ZNX5xznnPuVGAScKaZzTlC82HbFzNbDOxzzq0tdJV+5g2LvuR8xDl3OnAR8CUzW3iEtsO1LxGC06w/cc6dBnQRnGIZyKD1o9gCvRGYnDc9Cdg1RLW8H3vNbDxA7ve+3Pxh3T8zixKE+cPOuV/kZhdlXw7IvRT+LXAhxdmXjwCXmNnbBKcgzzezn1OcfcE5tyv3ex/wJMGph2LrSyPQmHvVB/A4QcAf934UW6CvBmaY2XQziwFLgaeGuKb34ings7nbnwV+mTd/qZnFzWw6MAP44xDUdxgzM4Jzgpuccz/IW1SMfRltZrW52+XA/wI2U4R9cc7d5pyb5JybRvB8eME59zcUYV/MrNLMqg/cBi4ANlBkfXHO7QF2mNkHc7MWAa9zIvox1P8Nfg//Pf44wTss3gS+NtT1FFDv/wF2AxmCv8SfA0YCvwHeyP2uz2v/tVzftgAXDXX9eXX9JcHLwNeAdbmfjxdpX+YBf8r1ZQPwjdz8outLn36dy8F3uRRdXwjOPb+a+9l44PldpH05FViTe4z9J1B3IvqhT4qKiJSIYjvlIiIiA1Cgi4iUCAW6iEiJUKCLiJQIBbqISIlQoIuIlAgFuohIiVCgi4iUiP8fFEYQoLLYcBYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test.drop(\"RefId\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.abs(1-preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "output3 = pd.DataFrame({\"RefId\": test.RefId, \"IsBadBuy\":preds[:,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>IsBadBuy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73016</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73019</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RefId  IsBadBuy\n",
       "0  73015       1.0\n",
       "1  73016       1.0\n",
       "2  73017       1.0\n",
       "3  73018       1.0\n",
       "4  73019       1.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "output3.to_csv(\"pysubmission3.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
